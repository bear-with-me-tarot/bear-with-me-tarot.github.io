
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>1.9. transformers</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="1.10. causal inference" href="ovw_causal_inference.html" />
    <link rel="prev" title="1.8. ml in medicine" href="ovw_ml_medicine.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    overview 👋
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="research_ovws.html">
   1. research_ovws
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_transfer_learning.html">
     1.1. transfer learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_disentanglement.html">
     1.2. disentanglement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_omics.html">
     1.3. omics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_complexity.html">
     1.4. complexity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_interesting_science.html">
     1.5. interesting science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_dl_theory.html">
     1.6. dl theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_scat.html">
     1.7. scattering transform
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_ml_medicine.html">
     1.8. ml in medicine
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     1.9. transformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_causal_inference.html">
     1.10. causal inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_uncertainty.html">
     1.11. uncertainty
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_interp.html">
     1.12. interpretability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ovw_generalization.html">
     1.13. generalization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../cs/cs.html">
   2. cs
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/retrieval.html">
     2.1. info retrieval
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/data_structures.html">
     2.2. data structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/languages.html">
     2.3. languages
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/software.html">
     2.4. software engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/quantum.html">
     2.5. quantum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/algo.html">
     2.6. algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/graphs.html">
     2.7. graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/os.html">
     2.8. os
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/arch.html">
     2.9. architecture
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/reproducibility.html">
     2.10. reproducibility
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cs/comp_theory.html">
     2.11. cs theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../math/math.html">
   3. math
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/differential_equations.html">
     3.1. differential equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/proofs.html">
     3.2. proofs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/analysis.html">
     3.3. real analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/linear_algebra.html">
     3.4. linear algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/signals.html">
     3.5. signals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/optimization.html">
     3.6. optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/calculus.html">
     3.7. calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/chaos.html">
     3.8. chaos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../math/math_basics.html">
     3.9. math basics
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../stat/stat.html">
   4. stat
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/graphical_models.html">
     4.1. graphical models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/data_analysis.html">
     4.2. data analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/testing.html">
     4.3. testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/causal_inference.html">
     4.4. causal inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/info_theory.html">
     4.5. info theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/linear_models.html">
     4.6. linear models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/time_series.html">
     4.7. time series
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../stat/game_theory.html">
     4.8. game theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ml/ml.html">
   5. ml
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/kernels.html">
     5.1. kernels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/nlp.html">
     5.2. nlp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/comp_vision.html">
     5.3. computer vision
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/structure_ml.html">
     5.4. structure learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/classification.html">
     5.5. classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/unsupervised.html">
     5.6. unsupervised
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/deep_learning.html">
     5.7. deep learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/feature_selection.html">
     5.8. feature selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/learning_theory.html">
     5.9. learning theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml/evaluation.html">
     5.10. evaluation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ai/ai.html">
   6. ai
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/search.html">
     6.1. search
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/decisions_rl.html">
     6.2. decisions, rl
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/fairness_sts.html">
     6.3. fairness, sts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/cogsci.html">
     6.4. cogsci
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/ai_futures.html">
     6.5. ai futures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/logic.html">
     6.6. logic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/philosophy.html">
     6.7. philosophy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/psychology.html">
     6.8. psychology
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ai/knowledge_rep.html">
     6.9. representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../neuro/neuro.html">
   7. neuro
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/disease.html">
     7.1. disease
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/brain_basics.html">
     7.2. brain basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/vissci.html">
     7.3. vision
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/comp_neuro.html">
     7.4. comp neuro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/sensory_input.html">
     7.5. sensory input
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/memory.html">
     7.6. memory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/motor.html">
     7.7. motor system
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../neuro/development.html">
     7.8. development
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/csinva/csinva.github.io"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/notes/research_ovws/ovw_transformers.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#papers">
   1.9.1. papers
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#high-performing">
     1.9.1.1. high-performing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#external-knowledge-tool-use-grounding">
     1.9.1.2. external knowledge / tool use / grounding
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prompting">
   1.9.2. prompting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#auto-prompting">
     1.9.2.1. (auto)prompting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#llm-chaining-decoding">
     1.9.2.2. llm chaining / decoding
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#llm-querying-causal-inference">
     1.9.2.3. llm querying / causal inference
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#misc">
   1.9.3. misc
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#direct-weight-inspection">
     1.9.3.1. direct weight inspection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#attention-variants">
     1.9.3.2. attention variants
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#editing">
     1.9.3.3. editing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#debugging-interpretation">
     1.9.3.4. debugging / interpretation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#symbolic-reasoning">
     1.9.3.5. symbolic reasoning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adaptation-transfer">
     1.9.3.6. adaptation / transfer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-merging-mixture-of-experts-moe-routing">
     1.9.3.7. model merging / mixture of experts (MoE) / routing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#embeddings">
     1.9.3.8. embeddings
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pruning">
     1.9.3.9. pruning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applications">
   1.9.4. applications
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset-module-explanation">
     1.9.4.1. dataset / module explanation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learning-algorithms">
     1.9.4.2. learning algorithms
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cool-tasks">
     1.9.4.3. cool tasks
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tabular-data">
     1.9.4.4. tabular data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#llm-limitations-perspectives">
     1.9.4.5. llm limitations / perspectives
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#text-explanations-pre-cot">
     1.9.4.6. text explanations (pre-CoT)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clinical-papers">
     1.9.4.7. clinical papers
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-with-llms">
     1.9.4.8. evaluating with LLMs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#privacy">
     1.9.4.9. privacy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#paper-parsing">
     1.9.4.10. paper parsing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#basics">
   1.9.5. basics
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mathematical-overview-of-transformers-formal-algorithms-for-transformers">
     1.9.5.1. mathematical overview of transformers (Formal Algorithms for Transformers)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visual-explanation-notes-on-article-by-jay-allamar">
     1.9.5.2. visual explanation (notes on article by jay allamar)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#huggingface-tutorial">
     1.9.5.3. huggingface tutorial
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pre-transformer-nlp-models">
     1.9.5.4. pre-transformer nlp models
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>transformers</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#papers">
   1.9.1. papers
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#high-performing">
     1.9.1.1. high-performing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#external-knowledge-tool-use-grounding">
     1.9.1.2. external knowledge / tool use / grounding
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prompting">
   1.9.2. prompting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#auto-prompting">
     1.9.2.1. (auto)prompting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#llm-chaining-decoding">
     1.9.2.2. llm chaining / decoding
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#llm-querying-causal-inference">
     1.9.2.3. llm querying / causal inference
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#misc">
   1.9.3. misc
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#direct-weight-inspection">
     1.9.3.1. direct weight inspection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#attention-variants">
     1.9.3.2. attention variants
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#editing">
     1.9.3.3. editing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#debugging-interpretation">
     1.9.3.4. debugging / interpretation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#symbolic-reasoning">
     1.9.3.5. symbolic reasoning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adaptation-transfer">
     1.9.3.6. adaptation / transfer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-merging-mixture-of-experts-moe-routing">
     1.9.3.7. model merging / mixture of experts (MoE) / routing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#embeddings">
     1.9.3.8. embeddings
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pruning">
     1.9.3.9. pruning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applications">
   1.9.4. applications
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset-module-explanation">
     1.9.4.1. dataset / module explanation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learning-algorithms">
     1.9.4.2. learning algorithms
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cool-tasks">
     1.9.4.3. cool tasks
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tabular-data">
     1.9.4.4. tabular data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#llm-limitations-perspectives">
     1.9.4.5. llm limitations / perspectives
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#text-explanations-pre-cot">
     1.9.4.6. text explanations (pre-CoT)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clinical-papers">
     1.9.4.7. clinical papers
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-with-llms">
     1.9.4.8. evaluating with LLMs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#privacy">
     1.9.4.9. privacy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#paper-parsing">
     1.9.4.10. paper parsing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#basics">
   1.9.5. basics
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mathematical-overview-of-transformers-formal-algorithms-for-transformers">
     1.9.5.1. mathematical overview of transformers (Formal Algorithms for Transformers)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visual-explanation-notes-on-article-by-jay-allamar">
     1.9.5.2. visual explanation (notes on article by jay allamar)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#huggingface-tutorial">
     1.9.5.3. huggingface tutorial
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pre-transformer-nlp-models">
     1.9.5.4. pre-transformer nlp models
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="transformers">
<h1><span class="section-number">1.9. </span>transformers<a class="headerlink" href="#transformers" title="Permalink to this headline">#</a></h1>
<section id="papers">
<h2><span class="section-number">1.9.1. </span>papers<a class="headerlink" href="#papers" title="Permalink to this headline">#</a></h2>
<p>See related papers in the <a class="reference external" href="https://csinva.io/notes/research_ovws/ovw_interp.html">📌 interpretability</a> page.</p>
<section id="high-performing">
<h3><span class="section-number">1.9.1.1. </span>high-performing<a class="headerlink" href="#high-performing" title="Permalink to this headline">#</a></h3>
<p><strong>nlp</strong> (see also <a class="reference external" href="https://medium.com/nlplanet/a-brief-timeline-of-nlp-from-bag-of-words-to-the-transformer-family-7caad8bbba56">this link</a>)</p>
<ul class="simple">
<li><p>early papers</p>
<ul>
<li><p>attention is all you need (<a class="reference external" href="https://arxiv.org/abs/1706.03762">vaswani et al. 2017</a>) - initial transformer</p>
<ul>
<li><p>encoder-decoder transformer for seq-to-seq (most new models don’t have  special encoder-decoder structure for translation)</p></li>
<li><p>Semi-supervised Sequence Learning (<a class="reference external" href="https://arxiv.org/abs/1511.01432">dai &amp; quoc le, 2015</a>)</p>
<ul>
<li><p>context vector is weighted sum of context vector at each word</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1801.06146">ULMFiT</a> (howard &amp; ruder, 2018)</p></li>
</ul>
</li>
<li><p>BERT (<a class="reference external" href="https://arxiv.org/abs/1810.04805">devlin et al. 2018</a>) - semi-supervised learning (predict masked word - this is bidirectional) + supervised finetuning</p>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/abs/1907.11692">roberta</a> (liu et al. 2019)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1910.13461">BART</a> (lewis et al. 2019) - generalizes BERT with sequence-to-squence training: train by (1) corrupting text then (2) reconstruct the original text</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1802.05365">ELMo</a> (peters…zettlemoyer, 2018) - no word embeddings - train embeddings w/ bidirectional lstm (on language modeling)</p></li>
<li><p>XLNet (<a class="reference external" href="https://arxiv.org/abs/1906.08237">yang…quoc le, 2020</a>)</p></li>
</ul>
</li>
<li><p>GPT-4 (openai, 2023) - adds multimodal understanding + boosts context length to 32k</p>
<ul>
<li><p>GPT-3 (<a class="reference external" href="https://arxiv.org/abs/2005.14165?2">brown et al. 2020</a>) - identitical to GPT-2 except larger and replaces dense attention with sparse attention</p>
<ul>
<li><p>sizes: largest has 175B params, 96 layers, 96 heads in each layer, head with dim 128, vocab size ~50k</p></li>
</ul>
</li>
<li><p>InstructGPT (<a class="reference external" href="https://arxiv.org/abs/2203.02155">ouyang…lowe, 2022</a>)</p></li>
<li><p>GPT-2 (<a class="reference external" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">radford et al. 2018</a>)</p></li>
<li><p>GPT (<a class="reference external" href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">radford et al. 2018</a>)</p></li>
<li><p>Gopher (<a class="reference external" href="https://arxiv.org/abs/2112.11446">deepmind, 2021</a>) - basically gpt-3 with slight mods (replace layernorm by RMSnorm, different positional embeddings)</p></li>
<li><p>open-source (from meta ai): <a class="reference external" href="https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/">LlaMa 2</a>, <a class="reference external" href="https://scontent-sea1-1.xx.fbcdn.net/v/t39.8562-6/333078981_693988129081760_4712707815225756708_n.pdf?_nc_cat=108&amp;ccb=1-7&amp;_nc_sid=ad8a9d&amp;_nc_ohc=0JlbsRuMCfYAX89GkW5&amp;_nc_ht=scontent-sea1-1.xx&amp;oh=00_AfAKI4SBnQesKWtXsUVxzF9w_IT_qOgOTTKNpeZRptOBuw&amp;oe=63FDD562">LLaMa</a>, <a class="reference external" href="https://arxiv.org/abs/2212.12017">OPT-IML</a>, <a class="reference external" href="https://arxiv.org/abs/2205.01068">OPT</a></p>
<ul>
<li><p><a class="reference external" href="https://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf">GPT4All</a> (LLaMA 7B finetuned on code/stories/dialogue)</p></li>
</ul>
</li>
</ul>
</li>
<li><p>ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators (<a class="reference external" href="https://arxiv.org/abs/2003.10555">clark…quoc le, chris manning, 2020</a>)</p>
<ul>
<li><p>more efficient: rather than standard masked training, use generator-discriminator setup for “token detection”</p>
<ul>
<li><p>generator replaces many masked tokens with plausible samples - train with MLM</p></li>
<li><p>discriminator tries to guess which tokens were the masked ones - this is the main model that gets used</p></li>
</ul>
</li>
</ul>
</li>
<li><p>LongNet: Scaling Transformers to 1,000,000,000 Tokens (<a class="reference external" href="https://arxiv.org/abs/2307.02486">ding, …, wei, 2023</a>) - multiscale attention similar to wavelets</p>
<ul>
<li><p>Longformer: The Long-Document Transformer (<a class="reference external" href="https://arxiv.org/abs/2004.05150">Beltagy, Peters, &amp; Cohan 2020</a>) - processes very long contexts</p></li>
<li><p>Lost in the Middle: How Language Models Use Long Contexts (<a class="reference external" href="https://arxiv.org/abs/2307.03172">liu…petroni, liang, 2023</a>)</p></li>
</ul>
</li>
<li><p>PaLM: Scaling Language Modeling with Pathways (<a class="reference external" href="https://arxiv.org/abs/2204.02311">Google 2022</a>) - 540 Billion params</p>
<ul>
<li><p>pathways hardware center allows for fast/efficient training</p></li>
<li><p>discontinuous improvements - at some point large model improves</p></li>
<li><p>prompt engineering: “Explain yourself” - lets it explain jokes</p></li>
<li><p>Chinchilla: Training Compute-Optimal Large Language Models (<a class="reference external" href="https://arxiv.org/abs/2203.15556">DeepMind 2022</a>)</p>
<ul>
<li><p>“chinchilla scaling laws” - for compute-optimal training, the model size and the number of training tokens should be scaled equally</p></li>
</ul>
</li>
</ul>
</li>
<li><p>T0 (<a class="reference external" href="https://arxiv.org/pdf/2110.08207.pdf">sanh…rush, 2022</a>) - multitask training enables better zero-shot generalization</p>
<ul>
<li><p>T5 (<a class="reference external" href="https://jmlr.org/papers/volume21/20-074/20-074.pdf">raffel…liu, 2020</a>) – text-to-text transfer transformer</p></li>
<li><p>UL2: Unifying Language Learning Paradigms (<a class="reference external" href="https://arxiv.org/abs/2205.05131">tay…metzler, 2022</a>) - open-source 20B model, beats GPT-3 at zero-shot</p></li>
</ul>
</li>
<li><p>more effective training</p>
<ul>
<li><p>instruction following</p>
<ul>
<li><p>FLAN-PaLM: Scaling Instruction-Finetuned Language Models (<a class="reference external" href="https://arxiv.org/abs/2210.11416">chung, …, quoc le, jason wei, 2022</a>) - finetune with datasets phrased as instructions</p>
<ul>
<li><p>FLAN (<a class="reference external" href="https://arxiv.org/abs/2109.01652">wei, …, le, 2021</a>) - finetune on instructions to follows instructions</p></li>
</ul>
</li>
</ul>
</li>
<li><p>human feedback</p>
<ul>
<li><p>Learning to summarize with human feedback (<a class="reference external" href="https://proceedings.neurips.cc/paper/2020/hash/1f89885d556929e98d3ef9b86448f951-Abstract.html">OpenAI, 2020</a>)</p></li>
<li><p>Can language models learn from explanations in context? (<a class="reference external" href="https://arxiv.org/abs/2204.02329">lampinen et al. 2022</a>)</p></li>
<li><p>natural language feedback (<a class="reference external" href="https://arxiv.org/abs/2204.14146">scheurer et al. 2022</a>) - makes training more efficient</p>
<ul>
<li><p>Training Language Models with Language Feedback at Scale (<a class="reference external" href="https://arxiv.org/pdf/2303.16755.pdf">scheurer et al. 2023</a>)</p></li>
</ul>
</li>
<li><p>Explanation-based Finetuning Makes Models More Robust to Spurious Cues (<a class="reference external" href="https://arxiv.org/abs/2305.04990">ludan…callison-burch, 2023</a>)</p>
<ul>
<li><p>Post hoc explanations of language models can improve language models (<a class="reference external" href="https://arxiv.org/abs/2305.11426">krishna…singh, lakkaraju, 2023</a>) - use rationales as corrective signals for LLMs</p></li>
</ul>
</li>
<li><p>RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback (<a class="reference external" href="https://arxiv.org/abs/2309.00267">lee…rastogi, 2023</a>)</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>other</strong></p>
<ul>
<li><p>text-vision models</p>
<ul class="simple">
<li><p>CLIP (<a class="reference external" href="https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language.pdf">radford et al. 2021</a>) - jointly train text/images</p>
<ul>
<li><p>batch-based loss: encodings from same image/text pair should be close while encodings across different examples in the batch should be different</p></li>
<li><p>note: empirically works better with very large batch size</p></li>
</ul>
</li>
<li><p>DALL-E 2 (<a class="reference external" href="https://openai.com/dall-e-2/">OpenAI, 2022</a>)</p>
<ul>
<li><p>clip is foundation as generative model</p></li>
<li><p>generates text + image embeddings</p></li>
<li><p>“prior network” maps text embedding to image embedding</p></li>
<li><p>adds diffusion model</p></li>
<li><p>Stable diffusion (<a class="reference external" href="https://stability.ai/blog/stable-diffusion-public-release">stability.ai, 2022</a>) - open-source recreation, now highly optimized for speed</p></li>
<li><p>Imagen (<a class="reference external" href="https://arxiv.org/abs/2205.11487">google, 2022</a>)</p></li>
</ul>
</li>
<li><p>BLIP-2 (<a class="reference external" href="https://arxiv.org/abs/2301.12597">salesforce, 2023</a>) - Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</p>
<ul>
<li><p>BEiT-3 (<a class="reference external" href="https://arxiv.org/abs/2208.10442">2022</a>) - treat vision as language and large-scale multimodal training</p></li>
<li><p>outperforms <a class="reference external" href="https://arxiv.org/abs/2204.14198">Flamingo: a Visual Language Model for Few-Shot Learning</a> (2022), which uses more domain knowledge to connect vision &amp; language</p></li>
</ul>
</li>
<li><p>video</p>
<ul>
<li><p>Text-To-4D Dynamic Scene Generation (<a class="reference external" href="https://arxiv.org/abs/2301.11280v1">meta, 2023</a>)</p></li>
</ul>
</li>
</ul>
</li>
<li><p>vision</p>
<ul class="simple">
<li><p>VIT: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (<a class="reference external" href="https://arxiv.org/abs/2010.11929">dosoviskiy, …, houlsby, 2020</a>)</p>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/abs/1904.09925">attention augmentation to resnet</a> for vision (bello…quoc le, 2020)</p></li>
<li><p>here, people call image patches “tokens”</p></li>
</ul>
</li>
<li><p>DINO <a class="reference external" href="https://arxiv.org/abs/2104.14294">Emerging Properties in Self-Supervised Vision Transformers</a> (caron…joulin, 2021)</p></li>
<li><p>Masked Autoencoders Are Scalable Vision Learners (<a class="reference external" href="https://arxiv.org/abs/2111.06377">he…dollar, girshick, 2021</a>) - BERT-style training</p>
<ul>
<li><p>speed up by not applying encoder to mask tokens + adding mask to a lot of the data (like 75%)</p></li>
<li><p>really good results without much data</p></li>
</ul>
</li>
<li><p>spatial transformers networks (<a class="reference external" href="https://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf">deepmind, 2015</a>)</p></li>
</ul>
</li>
<li><p>rl</p>
<ul class="simple">
<li><p>AdA: Human-Timescale Adaptation in an Open-Ended Task Space (<a class="reference external" href="https://arxiv.org/abs/2301.07608">deepmind, 2023</a>)</p></li>
<li><p>GATO: <a class="reference external" href="https://arxiv.org/abs/2205.06175">A Generalist Agent</a> (deepmind, 2022) - single agent plays many different video games</p>
<ul>
<li><p>different modalities are converted to tokens differently (e.g. image patches are fed through resnet)</p></li>
</ul>
</li>
<li><p>In-context Reinforcement Learning with Algorithm Distillation (<a class="reference external" href="https://arxiv.org/abs/2210.14215">laskin, wang, …, sahni, satinder singh, mnih, 2022, deepmind</a>) - learn to improve an RL algorithm</p>
<ul>
<li><p>put history of (observation, action, reward) sequences into context and then use them to predict new action given new observation</p></li>
</ul>
</li>
<li><p>Decision Transformer: Reinforcement Learning via Sequence Modeling (<a class="reference external" href="https://arxiv.org/pdf/2106.01345.pdf">chen, lu, …abbeel, srinivas, mordatch, 2021</a>) - transformer that predicts what the next highest reward step is instead of the next word</p></li>
</ul>
</li>
<li><p>question-answering (now just done with generic LLMs)</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/2005.00700">UnifiedQA: Crossing Format Boundaries With a Single QA System</a> (khashabi…hajishirzi, 2020)</p></li>
</ul>
</li>
<li><p>dialog</p>
<ul class="simple">
<li><p>ChatGPT</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2206.11309">GODEL: Large-Scale Pre-Training for Goal-Directed Dialog</a> (baolin peng, galley, …, gao , 2022) - add grounded pre-training</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1706.05125">Deal or No Deal? End-to-End Learning for Negotiation Dialogues</a> (lewis…batra, 2017, Meta) - controversial paper where agents “make up their own language”</p>
<ul>
<li><p>this is pre-transformers</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2206.14858">MINERVA: Solving Quantitative Reasoning Problems with Language Models</a> (google, 2022) - train on well-parsed, domain-specific data (math arxiv) to solve math-reasoning problems</p>
<ul class="simple">
<li><p>autoformalization (<a class="reference external" href="https://arxiv.org/abs/2205.12615">wu…, szegedy, 2022</a>) - translating from natural language math to formal language</p></li>
<li><p>produce sql/python that then finds an answer (<a class="reference external" href="https://arxiv.org/abs/2210.02875">cheng…zettlemoyer, smith, yu, 2022</a>)</p></li>
</ul>
</li>
<li><p>CODEX: <a class="reference external" href="https://arxiv.org/abs/2107.03374">Evaluating Large Language Models Trained on Code</a> (2021, openai)</p>
<ul>
<li><p>Repair Is Nearly Generation: Multilingual Program Repair with LLMs (<a class="reference external" href="https://arxiv.org/abs/2208.11640">Joshi et al. 2022</a>)</p></li>
<li><p>Improving automatically generated code from Codex via Automated Program Repair (<a class="reference external" href="https://arxiv.org/abs/2205.10583">Fan et al. 2022</a>) - use automated program repair to tweak codex outputs to make them better</p></li>
<li><p>Generating Question Titles for Stack Overflow from Mined Code Snippets (<a class="reference external" href="https://dl.acm.org/doi/abs/10.1145/3401026?casa_token=FEWYSo9ZmNIAAAAA:-_ZIkXQVUR3xYaB3NtrzBv0jZU6IZ6O4f_W_ZDtb6TipLBV4YHB-0lbO1JU8T9wwIl_jLBS3ts0">Gao et al. 2020</a>)</p></li>
<li><p>Automatic Program Repair with OpenAI’s Codex: Evaluating QuixBugs (<a class="reference external" href="https://arxiv.org/abs/2111.03922">Prenner &amp; Robbes, 2021</a>)</p>
<ul>
<li><p>use prompt like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#### fix the bug in the following function</span>
<span class="o">&lt;</span><span class="n">buggy</span> <span class="n">function</span> <span class="ow">and</span><span class="o">/</span><span class="ow">or</span> <span class="n">docstring</span> <span class="n">here</span><span class="o">&gt;</span>
<span class="c1">#### fixed function</span>
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>program synthesis <a class="reference external" href="https://arxiv.org/abs/2108.07732">arxiv.org/abs/2108.07732</a> - formalize natural language into runnable code</p></li>
</ul>
</li>
<li><p>science</p>
<ul class="simple">
<li><p>Galactica: A Large Language Model for Science (<a class="reference external" href="https://galactica.org/static/paper.pdf">taylor…, stojnic, 2022, meta ai</a>) - trained on mostly papers + some knowledge bases (e.g. proteins)</p>
<ul>
<li><p>Nougat: Neural Optical Understanding for Academic Documents (<a class="reference external" href="https://arxiv.org/abs/2308.13418">blecher…scialom, sojnic, 2023</a>)</p></li>
</ul>
</li>
</ul>
</li>
<li><p>music</p>
<ul class="simple">
<li><p>MusicLM: Generating Music From Text (<a class="reference external" href="https://arxiv.org/abs/2301.11325">google, 2023</a>)</p></li>
<li><p>Jukebox: A Generative Model for Music (<a class="reference external" href="https://arxiv.org/abs/2005.00341">openai, 2020</a>)</p></li>
</ul>
</li>
<li><p>summarization / keywords</p>
<ul class="simple">
<li><p>KeyBERT: Minimal keyword extraction with BERT (<a class="reference external" href="https://github.com/MaartenGr/KeyBERT">grootendorst, 2020</a>)</p></li>
</ul>
</li>
<li><p>text-to-speech</p>
<ul class="simple">
<li><p>Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale (<a class="reference external" href="https://research.facebook.com/publications/voicebox-text-guided-multilingual-universal-speech-generation-at-scale/">meta, 2023</a>)</p></li>
</ul>
</li>
</ul>
</section>
<section id="external-knowledge-tool-use-grounding">
<h3><span class="section-number">1.9.1.2. </span>external knowledge / tool use / grounding<a class="headerlink" href="#external-knowledge-tool-use-grounding" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>private</p>
<ul>
<li><p><a class="reference external" href="https://www.perplexity.ai/">https://www.perplexity.ai/</a> - nice demo adding citation to each fact</p></li>
<li><p><a class="reference external" href="https://you.com">https://you.com</a></p></li>
<li><p><a class="reference external" href="https://github.com/hwchase17/langchain">langchain</a> library</p></li>
<li><p><a class="reference external" href="https://www.fixie.ai/">https://www.fixie.ai/</a> - provide tools for wrapping APIs in LLM + interaction through router (also default modules for stateful storage, user identity, etc.)</p></li>
</ul>
</li>
<li><p>review</p>
<ul>
<li><p>Augmented Language Models: a Survey (<a class="reference external" href="https://arxiv.org/abs/2302.07842">meta, 2023</a>) – 3 categories: reasoning, tools, action</p></li>
</ul>
</li>
<li><p>Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP (<a class="reference external" href="https://arxiv.org/abs/2212.14024">khattab, …, liang, potts, &amp; zaharia, 2022</a>) - use high-level programs to use multiple steps between retrieving and reading</p></li>
<li><p>Toolformer: Language Models Can Teach Themselves to Use Tools (<a class="reference external" href="https://arxiv.org/abs/2302.04761">meta, 2023</a>) - model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction</p>
<ul>
<li><p>Given input, sample position and API call candidates, try them all, and filter out ones which do not reduce next-token loss</p>
<ul>
<li><p>put correct API calls into prompt, e.g. Pittsburgh is also known as <code class="docutils literal notranslate"><span class="pre">[QA(What</span> <span class="pre">...?→</span> <span class="pre">Steel</span> <span class="pre">City)]</span></code> the Steel City.</p></li>
</ul>
</li>
<li><p>Training</p>
<ul>
<li><p>start with few human-written examples of API use</p></li>
<li><p>LLM generates more uses</p></li>
<li><p>self-supervised loss determines which calls help with future-token prediction</p></li>
</ul>
</li>
<li><p>Atlas: Few-shot Learning with Retrieval Augmented Language Models (<a class="reference external" href="https://arxiv.org/abs/2208.03299">meta, 2022</a>)</p></li>
</ul>
</li>
<li><p>retreival-augmented in-context learning (put retrieved info into context, or something very similar)</p>
<ul>
<li><p>REALM (<a class="reference external" href="https://arxiv.org/abs/2002.08909">guu, …, chang, 2020</a>) - retrieves document chunks from corpus and adds them to context, for open-domain QA</p></li>
<li><p>RETRO (<a class="reference external" href="https://arxiv.org/abs/2112.04426">deepmind, 2022</a>) - nearest neighbors to model’s input are retrieved, encoded, and conditioned on with chunked cross-attention</p></li>
<li><p>Decomposed prompting (<a class="reference external" href="https://arxiv.org/pdf/2210.02406.pdf">khot et al., 2022</a>) - decompose tasks via prompting which are delegated to a shared library of prompting-based LLMs dedicated to these sub-tasks</p></li>
<li><p>LLM-Augmenter (<a class="reference external" href="https://arxiv.org/abs/2302.12813">peng, galley…gao, 2023</a>) -  (1) consolidates evidence from external knowledge for the LLM to generate responses grounded in evidence, and (2) revising LLM’s (candidate) responses using automated feedback</p></li>
</ul>
</li>
<li><p>knowledge base triplets</p>
<ul>
<li><p>Relational Memory-Augmented Language Models (<a class="reference external" href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00476/110997/Relational-Memory-Augmented-Language-Models">liu, yogatama, &amp; blunsom, 2022</a>) - integrate knowledge base triplets with LLM</p></li>
<li><p>DRAGON: Deep Bidirectional Language-Knowledge Graph Pretraining (<a class="reference external" href="https://arxiv.org/abs/2210.09338">yasanaga, …, manning, liang, leskovec, 2022</a>)</p></li>
</ul>
</li>
<li><p>webgpt (<a class="reference external" href="https://arxiv.org/abs/2112.09332">nakano, …, schulman, 2022, OpenAI</a>) - allows google search to add world info</p>
<ul>
<li><p>Internet-augmented language models <a class="reference external" href="https://arxiv.org/pdf/2203.05115.pdf">Lazaridou et al., 2022</a></p></li>
<li><p>GopherCite (<a class="reference external" href="https://arxiv.org/abs/2203.11147">menick, …, mcaleese, 2022, Deepmind</a>) - generate answers + link/relevant snippet when making predictions (trained with RL from human preferences )</p></li>
<li><p>LaMDA (<a class="reference external" href="https://arxiv.org/abs/2201.08239">thoppilan, …, quoc le, 2022, google</a>) - allows google search to add world info (in a dialog model)</p>
<ul>
<li><p>this was the model that sparked the controversy about consciousness 🤔</p></li>
<li><p>A Neural Corpus Indexer for Document Retrieval (<a class="reference external" href="https://arxiv.org/abs/2206.02743">wang…yang, 2022</a>) - train model to directly spit out document IDs given queries</p></li>
</ul>
</li>
</ul>
</li>
<li><p>RLPG (<a class="reference external" href="https://arxiv.org/abs/2206.12839">shrivastava, larochelle, &amp; tarlow, 2022</a>) - for code-completion, retrieves functions from a repo</p></li>
<li><p>memorizing transformers (<a class="reference external" href="https://arxiv.org/abs/2203.08913">wu…szegedy, 2022</a>) - knn-based learned indexing + retrieval at training time</p>
<ul>
<li><p>at test time, you just need to index the entire context and the model will be able to use it</p></li>
<li><p>kNN Prompting: Learning Beyond the Context with Nearest Neighbor Inference (<a class="reference external" href="https://openreview.net/forum?id=fe2S7736sNS">xu…zhang, 2023</a>) - instead of verbalizer, use nearest-neighbor</p>
<ul>
<li><p>has dbpedia results</p></li>
</ul>
</li>
<li><p>kNN-Prompt: Nearest Neighbor Zero-Shot Inference (<a class="reference external" href="https://arxiv.org/pdf/2205.13792.pdf">shi…zettlemoyer, 2022</a>)</p></li>
</ul>
</li>
<li><p>self-verification</p>
<ul>
<li><p>Self-Refine: Iterative Refinement with Self-Feedback (<a class="reference external" href="https://arxiv.org/abs/2303.17651">madaan, …, clark, 2023</a>)</p></li>
<li><p>Self-Verification Improves Few-Shot Clinical Information Extraction (<a class="reference external" href="https://arxiv.org/abs/2306.00024">gero et al. 2023</a>)</p></li>
<li><p>SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models (<a class="reference external" href="https://arxiv.org/abs/2303.08896">manakul…gales, 2023</a>)</p></li>
</ul>
</li>
<li><p>ACT-1: Transformer for Actions (<a class="reference external" href="https://www.adept.ai/act">2022, Adept</a>) - transformer directly interacts with computer</p></li>
<li><p>ReAct: Synergizing Reasoning and Acting in Language Models (<a class="reference external" href="https://arxiv.org/abs/2210.03629">yao…cao, 2022</a>) - use LLMs to generate reasoning traces + task-specific actions in interleaved manner</p></li>
</ul>
</section>
</section>
<section id="prompting">
<h2><span class="section-number">1.9.2. </span>prompting<a class="headerlink" href="#prompting" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/dair-ai/Prompt-Engineering-Guide">https://github.com/dair-ai/Prompt-Engineering-Guide</a></p></li>
<li><p>Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing (<a class="reference external" href="https://arxiv.org/pdf/2107.13586.pdf">liu…neubig, 2021</a>)</p>
<ul>
<li><p>from <em>feature-engineering</em> -&gt; <em>architecture engineering</em> -&gt; <em>prompt engineering</em></p></li>
<li><p><img alt="prompting_typology" src="../../_images/prompting_typology.png" /></p></li>
</ul>
</li>
<li><p>LAMA <a class="reference external" href="https://arxiv.org/abs/1909.01066">Language Models as Knowledge Bases?</a> (petroni…riedel, 2019) - Proposes using fill-in-the-blank (cloze) prompts for extracting knowledge from large language models</p>
<ul>
<li><p>create LAMA probe - dataset of (subject, relation, object) triplets with templates – find that BERT can recall these relations</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2108.01928">How to Query Language Models?</a> (adolphs et al. 2021) - query LLMs by example (e.g. “Ronaldo plays for Portugal. Who does Neuer play for?”)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1911.12543">How Can We Know What Language Models Know?</a> (jiang … neubig, 2020)</p>
<ul>
<li><p>mining-based and paraphrasing-based methods to automatically generate high-quality diverse prompts</p></li>
<li><p>ensemble methods to combine answers from different prompts (e.g. avg logits and more)</p></li>
</ul>
</li>
<li><p>Noisy Channel Language Model Prompting for Few-Shot Text Classification (<a class="reference external" href="https://arxiv.org/pdf/2108.04106.pdf">min et al. 2022</a>)</p>
<ul>
<li><p>Querying <span class="math notranslate nohighlight">\(P(question|answer)\)</span> with Bayes rule outperforms standard querying <span class="math notranslate nohighlight">\(P(answer|question)\)</span></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2201.06009">memory-assisted prompt-editing</a> (madaan…yang, 2022) - allows model to “save things to memory” that get added to prompt when needed</p></li>
<li><p>Prompting Is Programming: A Query Language For Large Language Models (<a class="reference external" href="https://arxiv.org/abs/2212.06094">Beurer-Kellner, Fischer, &amp; Vechev, 2022</a>)</p></li>
</ul>
<section id="auto-prompting">
<h3><span class="section-number">1.9.2.1. </span>(auto)prompting<a class="headerlink" href="#auto-prompting" title="Permalink to this headline">#</a></h3>
<p><img alt="prompting_hierarchy" src="../../_images/prompting_hierarchy.png" /></p>
<ul class="simple">
<li><p>natural-language prompting</p>
<ul>
<li><p>iPrompt: Explaining Patterns in Data with Language Models via Interpretable Autoprompting (<a class="reference external" href="https://arxiv.org/abs/2210.01848">singh, morris, …gao, 2022</a>)</p></li>
<li><p>APE: Large Language Models Are Human-Level Prompt Engineers (<a class="reference external" href="https://arxiv.org/abs/2211.01910">zhou…ba, 2022</a>)</p>
<ul>
<li><p>similar to iPrompt, (1) propose prompt candidates with an LLM, (2) score the prompts by the accuracy they yield when using another LLM and (3) regenerate similar prompt candidates</p></li>
<li><p>experiments on instruction induction datasets + truthful QA</p></li>
</ul>
</li>
<li><p>FluentPrompt: Toward Human Readable Prompt Tuning (<a class="reference external" href="https://arxiv.org/abs/2212.10539">shi, …, zettlemoyer, 2022</a>) - use langevin sampling + fluency constraint to generate prompt</p>
<ul>
<li><p>experiments relatively weak: 3 sentiment datasets + autoprompt is the only baseline</p></li>
</ul>
</li>
<li><p>APO: Automatic Prompt Optimization with “Gradient Descent” and Beam Search (<a class="reference external" href="https://arxiv.org/pdf/2305.03495.pdf">pryzant…zeng, 2023</a>) - update prompts based on errors made by previous prompts</p></li>
<li><p>OPRO: Large Language Models as Optimizers (<a class="reference external" href="https://arxiv.org/abs/2309.03409">yang…quoc le, zhou, &amp; chen , 2023</a>) - add in past prompts with their scores during optimization</p></li>
<li><p>Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers (<a class="reference external" href="https://arxiv.org/abs/2309.08532">guo…yang, 2023</a>)</p></li>
<li><p>Language Models as Black-Box Optimizers for Vision-Language Models (<a class="reference external" href="https://arxiv.org/pdf/2309.05950v1.pdf">yu…pathak, &amp; ramanan, 2023</a>)</p></li>
</ul>
</li>
<li><p>discrete prompting</p>
<ul>
<li><p><a class="reference external" href="https://aclanthology.org/2020.emnlp-main.346/">AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts</a> (shin…sameer singh, 2020)</p>
<ul>
<li><p>select prompts from a fixed set of tokens (resulting prompts are not coherent)</p></li>
<li><p>only work on MLM</p></li>
<li><p>elicit sentiment / factual knowledge</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1908.07125">Universal Adversarial Triggers for Attacking and Analyzing NLP</a> (wallace…sameer singh, 2019) - find input-agnostic sequences of tokens that trigger a model to produce a specific prediction when concatenated to any input from a dataset</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2205.12548">RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning</a> (deng…hu, 2022)</p></li>
<li><p>LM-BFF: Making Pre-trained Language Models Better Few-shot Learners (<a class="reference external" href="https://arxiv.org/abs/2012.15723">gao et al. 2020</a>) - uses T5 to generate (i) template for the task (which might include a whole example or two) + (i) appropropriate label tokens in the vocabulary for the task (suffers from computationally intensive search + sub-optimal discrete space search)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2102.12206">PADA: Example-based Prompt Learning for on-the-fly Adaptation to Unseen Domains</a> (ben-david, …, reichart, 2022)</p></li>
</ul>
</li>
<li><p>prompt ensembles</p>
<ul>
<li><p>PromptBoosting: Black-Box Text Classification with Ten Forward Passes (<a class="reference external" href="https://arxiv.org/abs/2212.09257">hou, …, jacob andreas, …, zhang, 2022</a>) - get a small pool of prompts, learn a verbalizer (final classification layer) for each, then ensemble them with AdaBoost on LLM output</p>
<ul>
<li><p>people have studied many works on prompt ensembling (e.g. <a class="reference external" href="https://arxiv.org/abs/2104.08691">lester et al. 2021</a>)</p></li>
</ul>
</li>
<li><p>PRBOOST: Prompt-Based Rule Discovery and Boosting for Interactive Weakly-Supervised Learning (<a class="reference external" href="https://arxiv.org/abs/2203.09735">zhang…zhang, 2022</a>) - iteratively (1) select high-error examples, (2) have human label them as rules, and (3) use boosting to train model on the new rules + ensemble</p>
<ul>
<li><p>typical rule generation</p>
<ul>
<li><p>Snuba (<a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/31777681/">Varma and Ré, 2018</a>) generates heuristics based on a small labeled dataset with pre-defined rule types</p></li>
<li><p>TALLOR (<a class="reference external" href="https://arxiv.org/pdf/2107.02282.pdf">Li et al. 2021a</a>) &amp; GLaRA (<a class="reference external" href="https://arxiv.org/pdf/2104.06230.pdf">Zhao et al. 2021</a>) study rule expansion for NER problem based on lexical information and then select rules based on a hand-tuned threshold</p></li>
</ul>
</li>
</ul>
</li>
<li><p>PTR: Prompt Tuning with Rules for Text Classification (<a class="reference external" href="https://arxiv.org/abs/2105.11259">han et al. 2021</a>) – use logic rules to construct prompts with sub-prompts for many-class text classification (prompt is constructed hierarchically, but only one call is made to the LLM for inference)</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2101.00190">Prefix-Tuning: Optimizing Continuous Prompts for Generation</a> (li &amp; percy liang, 2021) – optimizes in continuous space for language generation tasks</p>
<ul>
<li><p>learn to map some parameters <span class="math notranslate nohighlight">\(\theta\)</span> through and MLP to generate a starting hidden state <span class="math notranslate nohighlight">\(h_i\)</span> – never actually sends the prefix through the network</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2110.08329">Control Prefixes for Parameter-Efficient Text Generation</a> (clive, cao, &amp; rei, 2022) - allow for adapting the prefix to each input example</p></li>
<li><p>DART Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners (<a class="reference external" href="https://arxiv.org/abs/2108.13161">zhang…chen, 2022</a>)</p>
<ul>
<li><p>reformulating NLP task into differentially optimizing the prompt template + target label (given a pre-trained model)</p></li>
<li><p>focus on smaller models (Roberta-large + GPT-2) + few training shots</p></li>
<li><p>fluency constraint to ensure association among prompt embeddings</p></li>
<li><p>P-Tuning – <a class="reference external" href="https://arxiv.org/abs/2103.10385">GPT Understands, Too</a> (liu et al. 2021) – use LSTM to generate prompt embeddings (don’t map to tokens)</p></li>
</ul>
</li>
<li><p>Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification (<a class="reference external" href="https://arxiv.org/abs/2108.02035">Hu et al. 2021</a>) – add knowledge-base info into the prompt search</p></li>
<li><p>Learning How to Ask: Querying LMs with Mixtures of Soft Prompts (<a class="reference external" href="https://arxiv.org/abs/2104.06599">Qin &amp; Eisner, 2021</a>)</p>
<ul>
<li><p>use continuous tokens and ensemble (don’t map back to words)</p></li>
</ul>
</li>
<li><p>WARP: Word-level Adversarial ReProgramming (<a class="reference external" href="https://arxiv.org/abs/2101.00121">Hambardzumyan et al. 2021</a>) - add continous tokens (don’t map back to words) + some task-specific parameters for better generalization</p></li>
<li><p>KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction (<a class="reference external" href="https://arxiv.org/abs/2104.07650">Chen et al. 2021</a>) – incorporate relations, visualize learned prompt vectors with t-SNE</p></li>
<li><p>Calibrate Before Use: Improving Few-Shot Performance of Language Models (<a class="reference external" href="https://arxiv.org/abs/2102.09690">zhao, …, dan klein, sameer singh, 2021</a>) - in order to make prompting easier, first calibrate output distr by making it uniform when given null inputs, e.g. “N/A”</p></li>
<li><p>misc</p>
<ul>
<li><p>SentiPrompt: Sentiment Knowledge Enhanced Prompt-Tuning for Aspect-Based Sentiment Analysis (<a class="reference external" href="https://arxiv.org/abs/2109.08306">Zhang et al. 2021</a>) – use sentiment knowledge penalties in the prompt</p></li>
<li><p>Meta-learning via Language Model In-context Tuning (<a class="reference external" href="https://arxiv.org/abs/2110.07814">Chen et al. 2022</a>) – Given new task with new instruction</p></li>
<li><p>Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm (<a class="reference external" href="https://arxiv.org/abs/2102.07350">Reynolds &amp; McDonell, 2021</a>) – define metaprompts as general wrappers around tasks e.g. “This problem asks us to”</p></li>
<li><p>Re3: Generating Longer Stories With Recursive Reprompting and Revision (<a class="reference external" href="https://arxiv.org/abs/2210.06774">Yang et al. 2022</a>) - generate summaries, then expand and revise with prompts</p></li>
<li><p>Directional Stimulus Prompting (<a class="reference external" href="https://arxiv.org/abs/2302.11520">li, baoling peng, …jianfeng gao, xifeng yan, 2023</a>) - generate hint keywords using small LLM that are put into the prompt when calling large LLM</p></li>
</ul>
</li>
<li><p>critiques of prompting</p>
<ul>
<li><p>Do Prompt-Based Models Really Understand the Meaning of their Prompts? (<a class="reference external" href="https://arxiv.org/abs/2109.01247">webson &amp; pavlick, 2022</a>) - models can learn fine with prompts that are intentionally irrelevant</p>
<ul>
<li><p>Are Language Models Worse than Humans at Following Prompts? It’s Complicated (<a class="reference external" href="https://arxiv.org/abs/2301.07085">webson, …, pavlick, 2023</a>)</p></li>
</ul>
</li>
<li><p>Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity (<a class="reference external" href="https://arxiv.org/abs/2104.08786">lu…riedel, stenetorp, 2021</a>)</p></li>
</ul>
</li>
<li><p>can benefit from training for promptability</p>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/abs/2104.04670">Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections</a> (zhong…klein, 2021)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2210.10258">Continued Pretraining for Better Zero- and Few-Shot Promptability</a> (wu…sameer singh, beltagy, 2022)</p></li>
</ul>
</li>
<li><p>Context-faithful Prompting for Large Language Models (<a class="reference external" href="https://arxiv.org/pdf/2303.11315.pdf">zhou, shang, poon &amp; chen, 2023</a>) - ask question in clever way to force LLM to follow it</p></li>
</ul>
</section>
<section id="llm-chaining-decoding">
<h3><span class="section-number">1.9.2.2. </span>llm chaining / decoding<a class="headerlink" href="#llm-chaining-decoding" title="Permalink to this headline">#</a></h3>
<p><strong>many notes are from this <a class="reference external" href="https://twitter.com/iraphas13/status/1551959289023016967">thread</a> on chaining models together</strong></p>
<ul>
<li><p>steering</p>
<ul>
<li><p>overviews</p>
<ul class="simple">
<li><p>Ai chains: Transparent and controllable human-ai interaction by chaining large language model prompts (<a class="reference external" href="https://dl.acm.org/doi/abs/10.1145/3491102.3517582">wu, terry, &amp; cai, 2022</a>) - chaining LLM steps together: output of one step becomes the input for the next</p>
<ul>
<li><p>interactive system where users can modify chains + their intermediate results – improves performance + human experience</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2207.10342">Language Model Cascades</a> (dohan…sutton, 2022) - treat chaining models as probabilistic programs</p>
<ul>
<li><p>use a probabilistic-programming language (PPL) to define a joint probability model on string-valued random variables, parameterized using LMs, and then condition this model on string-valued observations in order to compute a posterior over string-valued unknowns</p></li>
<li><p>self-PPLs extend probabilistic graphical models to support more complex joint distributions whose size and “shape” can itself be stochastic</p>
<ul>
<li><p>e.g., a graph unrolled for a random number of iterations, until a data-dependent stopping criterion is met</p></li>
<li><p>variables are all text: questions <span class="math notranslate nohighlight">\(Q\)</span>, answers <span class="math notranslate nohighlight">\(A\)</span>, and intermediate thoughts <span class="math notranslate nohighlight">\(T\)</span></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>posthoc</p>
<ul>
<li><p>2023</p>
<ul>
<li><p>Faithful Chain-of-Thought Reasoning (<a class="reference external" href="https://arxiv.org/abs/2301.13379">lyu et al. 2023</a>)</p></li>
<li><p>Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks (<a class="reference external" href="https://arxiv.org/abs/2211.12588">chen et al. 2022</a>)</p>
<p>PAL: Program-aided Language Models (<a class="reference external" href="https://arxiv.org/abs/2211.10435">gao…neubig, 2023</a>)</p>
</li>
<li><p>Language Models Don’t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting (<a class="reference external" href="https://arxiv.org/abs/2305.04388">turpin, …, bowman, 2023</a>)</p>
<ul class="simple">
<li><p>CoT explanations can be heavily influenced by biasing the model towards certain answers, thereby yielding invalid explanations</p></li>
<li><p>try biasing in 2 ways: answer is always (A), or setting where prompt suggests a certain answer</p></li>
</ul>
</li>
<li><p>faithfulness metric = model sensitivity to removing some of the explanation</p>
<ul class="simple">
<li><p>Question Decomposition Improves the Faithfulness of Model-Generated Reasoning (<a class="reference external" href="https://www-files.anthropic.com/production/files/question-decomposition-improves-the-faithfulness-of-model-generated-reasoning.pdf">anthropic, 2023</a>) - introduce factored decomposition to improve faithfulness metric</p></li>
<li><p>Measuring Faithfulness in Chain-of-Thought Reasoning (<a class="reference external" href="https://www-files.anthropic.com/production/files/measuring-faithfulness-in-chain-of-thought-reasoning.pdf">anthropic, 2023</a>) - in addition to just removing some of the explanation, also add mistakes to it / paraphrase it</p>
<ul>
<li><p>larger models become less faithful by this metric</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations (<a class="reference external" href="https://arxiv.org/abs/2307.08678">chen, zhong, …, steinhardt, yu, mckeown, 2023</a>)</p>
<ul class="simple">
<li><p>Logical Satisfiability of Counterfactuals for Faithful Explanations in NLI (<a class="reference external" href="https://ojs.aaai.org/index.php/AAAI/article/view/26174">sia…zettlemoyer, mathias, 2023</a>)</p></li>
</ul>
</li>
<li><p>Causal Proxy Models for Concept-based Model Explanations (<a class="reference external" href="https://proceedings.mlr.press/v202/wu23b.html">wu…potts, 2023</a>)</p></li>
<li><p>Two Failures of Self-Consistency in the Multi-Step Reasoning of LLMs (<a class="reference external" href="https://arxiv.org/abs/2305.14279">chen, …, bowman, cho, 2023</a>) - models fail at these 2 tasks:</p>
<ul class="simple">
<li><p>hypothetical consistency (the ability for a model to predict what its output would be in a hypothetical other context)</p></li>
<li><p>compositional consistency (consistency of a model’s outputs for a compositional task even when an intermediate step is replaced with the model’s output for that step)</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Chain of Thought Prompting (<a class="reference external" href="https://arxiv.org/abs/2201.11903">wei et al. 2022</a>)</p>
<ul class="simple">
<li><p>in few-shot prompts, don’t just provide answer but also reasoning</p></li>
<li><p>model output then provides reasoning + answer</p></li>
<li><p>Self-Consistency Improves Chain of Thought Reasoning in Language Models (<a class="reference external" href="https://arxiv.org/abs/2203.11171">wang, wei, schuurmans, quoc le, … zhou, 2022</a>) - use output samples rather than greedy and return the most consistent final answer in the set</p></li>
<li><p>Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them (<a class="reference external" href="https://arxiv.org/abs/2210.09261">suzgun, …, quoc le, …, jason wei, 2022</a>)</p></li>
<li><p><em>self-ask</em> (<a class="reference external" href="https://arxiv.org/pdf/2210.03350.pdf">Press et al., 2022</a>) - LLM asks itself (and then answers) follow-up questions before answering the initial question</p></li>
<li><p>Text Classification via Large Language Models (<a class="reference external" href="https://arxiv.org/pdf/2305.08377.pdf">sun…wang, 2023</a>) - add clues to the prompt</p></li>
<li><p>Let’s Do a Thought Experiment: Using Counterfactuals to Improve Moral Reasoning (<a class="reference external" href="https://arxiv.org/abs/2306.14308">ma, …, chen, 2023</a>) - counterfactuals help improve CoT</p></li>
<li><p>RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought (<span class="xref myst">xue et al. 2023</span>)</p></li>
<li><p>SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning (<a class="reference external" href="https://arxiv.org/abs/2308.00436">miao, teh, &amp; rainforth, 2023</a>)</p></li>
</ul>
</li>
<li><p>scratchpads <a class="reference external" href="https://arxiv.org/abs/2112.00114">Show Your Work: Scratchpads for Intermediate Computation with Language Models</a> (nye et al. 2021)</p></li>
<li><p>selection inference (<a class="reference external" href="https://arxiv.org/abs/2205.09712">creswell et al. 2022</a>) - generate set of facts, then iteratively generate inferences from the facts to yield the final answer</p></li>
<li><p>least-to-most prompting (<a class="reference external" href="https://arxiv.org/abs/2205.10625">zhou…quoc le et al. 2022</a>) - prompt LLM with context showing how to reduce into subproblems; then LLM sequentially solves the subproblems, using the previous answers</p></li>
<li><p>Generated Knowledge Prompting for Commonsense Reasoning (<a class="reference external" href="https://arxiv.org/abs/2110.08387">liu…hasjishirzi, 2021</a>) - generate knowledge from an LLM then provide it as additional input when answering a question</p></li>
<li><p>maieutic prompting (<a class="reference external" href="https://arxiv.org/abs/2205.11822">jung et al. 2022</a>) - generate a tree of all explanation of the form “True, because…”, “False, because…” then query LLM with these as prompts</p>
<ul class="simple">
<li><p>then use Max-SAT to try to satisfy as many relations between the model explanations as possible to come up with the true answer</p></li>
</ul>
</li>
<li><p>review on self-verification (<a class="reference external" href="https://arxiv.org/pdf/2308.03188.pdf">pan…wang, 2023</a>)</p>
<ul class="simple">
<li><p>LM vs LM: Detecting Factual Errors via Cross Examination (<a class="reference external" href="https://arxiv.org/abs/2305.13281">cohen et al. 2023</a>)</p>
<ul>
<li><p><a class="reference external" href="https://twitter.com/ChengleiSi/status/1664023767373299715">Thread</a> of papers combating hallucination</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>training</p>
<ul class="simple">
<li><p>verifiers (<a class="reference external" href="https://arxiv.org/abs/2110.14168">cobbe et al. 2021</a>) - train model to judge whether an answer and thought are likely to be “valid”</p></li>
<li><p>subgoal search (<a class="reference external" href="https://t.co/PCR4yexHti">czechowski et al. 2021</a>) - train model to generate subgoals then solve them in a graph</p></li>
<li><p>STaR “Self-taught reasoner” (<a class="reference external" href="https://arxiv.org/abs/2203.14465">zelikman…goodman, 2022</a>)</p>
<ul>
<li><p>first, finetune on observed <span class="math notranslate nohighlight">\((Q, T, A)\)</span> triplets, where <span class="math notranslate nohighlight">\(T\)</span> is a rationale</p></li>
<li><p>then, impute unknown <span class="math notranslate nohighlight">\(T_i\)</span> given dataset of pairs <span class="math notranslate nohighlight">\((Q_i, A_i)\)</span> by sampling until finding a <span class="math notranslate nohighlight">\(T_i\)</span> which leads to the correct answer</p></li>
</ul>
</li>
</ul>
</li>
<li><p>robotics-specific</p>
<ul class="simple">
<li><p>zero-shot planning (<a class="reference external" href="https://arxiv.org/abs/2201.07207">huang, abbeel, pathak, &amp; mordatch, 2022</a>)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2204.00598">socratic models</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2207.05608">Inner Monologue</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2103.01197">global workspace</a></p></li>
</ul>
</li>
<li><p>tree-related</p>
<ul class="simple">
<li><p>tree of thoughts (<a class="reference external" href="https://arxiv.org/abs/2305.10601">yao et al. 2023</a>) - LLM generates a tree of intermediate answers and perform steps such as backtracking</p></li>
<li><p>Graph of Thoughts: Solving Elaborate Problems with Large Language Models (<a class="reference external" href="https://arxiv.org/pdf/2308.09687.pdf">besta, .., hoefler, 2023</a>) - allows merging/looping in the tree, e.g. for sorting</p></li>
<li><p>Aug-tree (<a class="reference external" href="https://arxiv.org/abs/2209.11799">singh, askari, caruana, &amp; gao, 2023</a>)</p></li>
<li><p>frugalGPT (<a class="reference external" href="https://arxiv.org/pdf/2305.05176.pdf">chen, zaharia, &amp; zou, 2023</a>)</p>
<ul>
<li><p>3 components</p>
<ol class="simple">
<li><p>prompt adaptation - identify effective / shorter prompts (e.g. less demonstrations)</p></li>
<li><p>LLM approximation - create simpler/cheaper LLMs</p></li>
<li><p>LLM cascade - adaptively choose LLM based on query</p>
<ol class="simple">
<li><p>train “generation scoring function” - returns reliability score from 0 to 1 for each (question, answer)</p></li>
<li><p>router sequentially proceeds through LLM APIs, returning the answer if the reliability score is high enough</p></li>
</ol>
</li>
</ol>
</li>
<li><p>frugalML (<a class="reference external" href="https://proceedings.neurips.cc/paper/2020/hash/789ba2ae4d335e8a2ad283a3f7effced-Abstract.html">chen, zaharia, zou, 2020</a>) - tradeoff performance with budget for sequential cascade of API calls for single label</p>
<ul>
<li><p>FrugalMCT (<a class="reference external" href="https://proceedings.mlr.press/v162/chen22ad.html">chen, zaharia, zou, 2022</a>) - extends to multilabel</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="llm-querying-causal-inference">
<h3><span class="section-number">1.9.2.3. </span>llm querying / causal inference<a class="headerlink" href="#llm-querying-causal-inference" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>decoding</p>
<ul>
<li><p>Greedy - iteratively pick highest-probability token</p></li>
<li><p>Nucleus sampling: <a class="reference external" href="https://arxiv.org/abs/1904.09751">The Curious Case of Neural Text Degeneration</a> (holtzman…choi, 2019)</p></li>
<li><p>Contrastive decoding (<a class="reference external" href="https://arxiv.org/abs/2210.15097">li et al. 2022</a>) - decode based on the difference between a large and small LLM</p>
<ul>
<li><p>Context-aware decoding (<a class="reference external" href="https://arxiv.org/pdf/2305.14739.pdf">shi, …zettlemoyer, yih, 2023</a>) - the difference between the output probabilities when a model is used with and without context</p></li>
<li><p>DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models (<a class="reference external" href="https://arxiv.org/abs/2309.03883">chuang…he, 2023</a>) - contasting later layers with early layers can improve truthfulness</p></li>
</ul>
</li>
<li><p>Semantic Uncertainty (<a class="reference external" href="https://arxiv.org/abs/2302.09664">kuhn, gal, &amp; farquhar, 2023</a>) - yields uncertainties by incorporating linguistic invariances created by shared meanings</p></li>
<li><p>Minimum Bayes Risk Decoding (<a class="reference external" href="https://arxiv.org/abs/2211.07634">suzgun, …, jurafsky, 2022</a>) or (<a class="reference external" href="https://arxiv.org/pdf/2111.09388.pdf">freitag et al. 2022</a>)</p></li>
<li><p>A Frustratingly Simple Decoding Method for Neural Text Generation (<a class="reference external" href="https://arxiv.org/abs/2305.12675">yang, …, shi, 2023</a>) - build an anti-LM based on previously generated text and use this anti-LM to penalize future generation of what has been generated</p></li>
</ul>
</li>
<li><p>Can Large Language Models Infer Causation from Correlation? (<a class="reference external" href="https://arxiv.org/abs/2306.05836">jin…scholkopf, 2023</a>) - introduce Corr2Cause dataset (must infer causal graph from correlational statements), doesn’t test pre-existing knowledge</p></li>
<li><p>Causal Reasoning and Large Language Models: Opening a New Frontier for Causality (<a class="reference external" href="https://arxiv.org/abs/2305.00050">kiciman…tan, 2023</a>)</p>
<ul>
<li><p>LLMs to be used alongside existing causal methods, as a proxy for human domain knowledge and to reduce human effort in setting up a causal analysis</p>
<ul>
<li><p>cause-effect pairs, LLM has to discover from graph (tubingen benchmark, neuropathic pain, etc.)</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Zero-shot causal learning (<a class="reference external" href="https://arxiv.org/abs/2301.12292">nilforoshan…leskovec, 2023</a>)</p></li>
<li><p>Discovering Latent Knowledge in Language Models Without Supervision (<a class="reference external" href="https://arxiv.org/abs/2212.03827">burns, ye, klein, &amp; steinhardt, 2022</a>) - identify whether text is true or false directly from a model’s <em>unlabeled activations</em></p>
<ul>
<li><p>Inference-Time Intervention: Eliciting Truthful Answers from a Language Model (<a class="reference external" href="https://arxiv.org/abs/2306.03341">li…pfister, wattenberg, 2023</a>)</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.frontiersin.org/articles/10.3389/frai.2021.659622/full">InferBERT: A Transformer-Based Causal Inference Framework for Enhancing Pharmacovigilance</a> (wang…liu, 2021) - learn + test feature relationships from attention weights</p></li>
<li><p><a class="reference external" href="https://direct.mit.edu/coli/article/47/2/333/98518/CausaLM-Causal-Model-Explanation-Through">CausaLM: Causal Model Explanation Through Counterfactual Language Models</a> (2021) - produce example-level causal model explanations using models finetuned on auxiliary adversarial tasks derived from the causal graph of the problem</p></li>
<li><p>Investigating Gender Bias in Language Models Using Causal Mediation Analysis (<a class="reference external" href="https://proceedings.neurips.cc/paper/2020/file/92650b2e92217715fe312e6fa7b90d82-Paper.pdf">vig, …, shieber, 2020</a>)</p>
<ul>
<li><p>Applies causal mediation analysis to identify decisive neurons and attention heads responsible for gender bias in large language models</p></li>
<li><p>Identifies a small handful of decisive attention heads in this case</p></li>
</ul>
</li>
<li><p>Amnesic Probing: Behavioral Explanation with Amnesic Counterfactuals (<a class="reference external" href="https://arxiv.org/pdf/2006.00995.pdf">elazar, …, goldberg, 2021</a>) - measure the importance of specific info within a model by introducing a causal intervention to erase that information, then observing the causal effects</p></li>
</ul>
</section>
</section>
<section id="misc">
<h2><span class="section-number">1.9.3. </span>misc<a class="headerlink" href="#misc" title="Permalink to this headline">#</a></h2>
<section id="direct-weight-inspection">
<h3><span class="section-number">1.9.3.1. </span>direct weight inspection<a class="headerlink" href="#direct-weight-inspection" title="Permalink to this headline">#</a></h3>
<p>Overview of mechanistic interpretability (<a class="reference external" href="https://www.neelnanda.io/mechanistic-interpretability/favourite-papers">nanda, 2022+</a>) + review paper (<a class="reference external" href="https://arxiv.org/abs/2207.13243">rauker…hadfield-menell, 2023</a>)</p>
<ul class="simple">
<li><p>Transformer visualization via dictionary learning: contextualized embedding as a linear superposition of transformer factors (<a class="reference external" href="https://arxiv.org/abs/2103.15949">yun, chen, olshausen, lecun, 2021</a>) - investigate LLM embeddings of different words using dictionary learning</p>
<ul>
<li><p>LLMs produce interesting contextualized word embeddings</p></li>
<li><p>dictionary elements (of activations across layers) correspond to meaningful things</p></li>
<li><p>dictionary element has size <span class="math notranslate nohighlight">\(d\)</span>, the embedding size</p>
<ul>
<li><p>given list of sentences <span class="math notranslate nohighlight">\(S\)</span>, training matrix has size <span class="math notranslate nohighlight">\(\left(\underbrace{\text{num\_layers}}_{\text{12 for BERT}} \cdot \sum_{s \in S} \text{len(s)}\right) \times \underbrace{d}_{\text{768 for BERT}}\)</span></p></li>
</ul>
</li>
<li><p>dictionary coefficient: maps (text, layer, sequence_index) <span class="math notranslate nohighlight">\(\to\)</span> coefficient</p>
<ul>
<li><p>extract <span class="math notranslate nohighlight">\(d\)</span>-dimensional embedding for text at specified layer &amp; sequence_index</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Neuron-level Interpretation of Deep NLP Models: A Survey (<a class="reference external" href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00519/113852/Neuron-level-Interpretation-of-Deep-NLP-Models-A">sajjad et al. 2022</a>)</p>
<ul>
<li><p>previous works generally use pre-specified concepts, and focus on</p>
<ul>
<li><p>concept search - given a neuron find its concept(s)</p></li>
<li><p>neuron search - (ii) given a concept find its matching neuron(s)</p></li>
</ul>
</li>
<li><p>concept search</p>
<ul>
<li><p>visualization, e.g. <a class="reference external" href="https://www.semanticscholar.org/paper/Visualizing-and-Understanding-Recurrent-Networks-Karpathy-Johnson/40be3888daa5c2e5af4d36ae22f690bcc8caf600">karpathy, johnson, fei-fei li, 2015</a> visualize LSTM head response in text</p></li>
<li><p>elicit top-k ngram responses on a corpus, which are then labelled manually (<a class="reference external" href="https://www.semanticscholar.org/paper/Representation-of-Linguistic-Form-and-Function-in-K%C3%A1d%C3%A1r-Chrupa%C5%82a/9462eee3e5eff15df5e97c38e24072c65e581cee">kadar et al. 2017</a>)</p></li>
<li><p>elicit top-k activating sentences from a corpus, which are then summarized using a parse tree into a synthetic explanation (<a class="reference external" href="https://arxiv.org/pdf/1902.07249.pdf">na…kim, 2019</a>)</p>
<ul>
<li><p>limitation: the explanation may be ungrammatical and biased towards something arbitrary (like reptition)</p></li>
</ul>
</li>
<li><p>input maximization (e.g. textattack, <a class="reference external" href="https://www.semanticscholar.org/paper/Interpretable-Textual-Neuron-Representations-for-Poerner-Roth/36fc119ce631c3ec66866ce31918978824d05f78">poerner et al. 2018</a>)</p></li>
</ul>
</li>
<li><p>Evaluating Neuron Interpretation Methods of NLP Models (<a class="reference external" href="https://arxiv.org/abs/2301.12608">fan…sajjad, 2023</a>) - metric is how well evaluation from one method matches the other ones</p></li>
</ul>
</li>
<li><p>A Circuit for Indirect Object Identification in GPT-2 small (<a class="reference external" href="https://arxiv.org/abs/2211.00593">wang, …, steinhardt, 2022</a>)</p>
<ul>
<li><p>explanation encompasses 26 attention heads grouped into 7 main classes</p></li>
<li><p>task: indirect object identification - “When Mary and John went to the store, John gave a drink to ___” should be “Mary”</p></li>
<li><p>circuit</p>
<ul>
<li><p>identify all previous names</p></li>
<li><p>remove duplicated names</p></li>
<li><p>output remaining name</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Interpretability at Scale: Identifying Causal Mechanisms in Alpaca (<a class="reference external" href="https://arxiv.org/pdf/2305.08809.pdf">wu…, potts, goodman, 2023</a>) - propose boundless DAS and automatically identify a circuit for math</p>
<ul>
<li><p>builds on DAS (<a class="reference external" href="https://arxiv.org/abs/2303.02536">geiger, …goodman, 2023</a>)</p></li>
</ul>
</li>
<li><p>N2G: A Scalable Approach for Quantifying Interpretable Neuron Representations in Large Language Models (<a class="reference external" href="https://arxiv.org/abs/2304.12918">foote, nanda, …, barez, 2023</a>) - explain each neuron in a graph</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2211.07349">Finding Skill Neurons in Pre-trained Transformer-based Language Models</a> - some individual neurons are predictive of the final task (dubbed “skill neurons’)</p></li>
<li><p><strong><a class="reference external" href="https://transformer-circuits.pub/2021/framework/index.html">thread</a> (elhage…olah, 2021)</strong></p></li>
<li><p>all layers are same dimension and each attention block <strong>adds</strong> a vector to it</p></li>
<li><p>Although they’re parameterized as separate matrices, <span class="math notranslate nohighlight">\(W_O W_V\)</span> and <span class="math notranslate nohighlight">\(W_Q^T W_K\)</span> can always be thought of as individual, low-rank matrices</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(x \in \mathbb R^{d_{embed} \times d_{sequence}}\)</span>: <span class="math notranslate nohighlight">\(d_{embed}\)</span> can be hundreds - tens of thousands</p></li>
<li><p><span class="math notranslate nohighlight">\(W_Q, W_K, W_V \in \mathbb R^{d_{attn} \times d_{embed}}\)</span></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(W_Q^TW_k \in \mathbb R ^{d_{embed} \times d_{embed}}\)</span></p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(W_O \in \mathbb R^{d_{embed} \times d_{attn}}\)</span>: projects attention values back to embedding dimention</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(W_O W_V \in \mathbb R ^{d_{embed} \times d_{embed}}\)</span></p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(W_E \in \mathbb R^{d_{embed} \times d_{vocab}}\)</span> embeds initial tokens and <span class="math notranslate nohighlight">\(W_U \in \mathbb R^{d_{vocab} \times d_{embed}}\)</span> undoes the embedding</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(d_{vocab}\)</span> can be very large, e.g. 50k</p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(A = \text{softmax}(x^TW_Q^TW_kx) \in \mathbb R^{d_{sequence} \times d_{sequence}}\)</span></p></li>
</ul>
</li>
<li><p>if we have a 0-layer net (e.g. predict next token with linear layer given current token), we just learn bigram log-likelihood</p></li>
<li><p>2 circuits</p>
<ul>
<li><p>QK circuit determines which “source” token the present “destination” token attends back to and copies information from</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(W_{E}^{T} W_{Q}^{T} W_{K} W_{E} \in \mathbb R ^{d_{vocab} \times d_{vocab}}\)</span></p></li>
</ul>
</li>
<li><p>OV circuit describes what the resulting effect on the “out” predictions for the next token is</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(W_{U} W_{O} W_{V} W_{E} \in \mathbb R ^{d_{vocab} \times d_{vocab}}\)</span></p></li>
</ul>
</li>
</ul>
</li>
<li><p>if a single head increases the probability of both <code class="docutils literal notranslate"><span class="pre">keep…</span> <span class="pre">in</span> <span class="pre">mind</span></code> and <code class="docutils literal notranslate"><span class="pre">keep…</span> <span class="pre">at</span> <span class="pre">bay</span></code>, it <em>must</em> also increase the probability of <code class="docutils literal notranslate"><span class="pre">keep…</span> <span class="pre">in</span> <span class="pre">bay</span></code> and <code class="docutils literal notranslate"><span class="pre">keep…</span> <span class="pre">at</span> <span class="pre">mind</span></code></p></li>
<li><p><strong>induction heads</strong> search previous examples of present token</p>
<ul>
<li><p>If they don’t find it, they attend to the first token and do nothing</p></li>
<li><p>if they do find it, they then look at the <em>next</em> token and copy it. This allows them to repeat previous sequences of tokens, both exactly and approximately</p></li>
<li><p>sometimes can do some kind of “fuzzy” matching</p></li>
</ul>
</li>
<li><p>tensor/kronecker product <span class="math notranslate nohighlight">\(\bigotimes\)</span>:</p>
<ul>
<li><p>Left-right multiplying: Multiplying <span class="math notranslate nohighlight">\(x\)</span> by a tensor product <span class="math notranslate nohighlight">\(A \otimes W\)</span> is equivalent to simultaneously left and right multiplying: <span class="math notranslate nohighlight">\((A \otimes W) x=A x W^{T}\)</span></p></li>
<li><p>When we add them, it is equivalent to adding the results of this multiplication: <span class="math notranslate nohighlight">\(\left(A_{1} \otimes W_{1}+A_{2} \otimes W_{2}\right) x=A_{1} x W_{1}^{T}+A_{2} x W_{2}^{T}\)</span>
<strong><a class="reference external" href="https://transformer-circuits.pub/2022/solu/index.html">Softmax Linear Units</a></strong></p></li>
</ul>
</li>
<li><p>replacing activation function with softmax linear unit increases fraction of MLP neurons which are “interpretable”, i.e. correspond to meaningful features</p>
<ul>
<li><p>however, may “hide” some non-neuron-aligned features by decreasing their magnitude and then later recovering it with LayerNorm</p></li>
</ul>
</li>
<li><p>the presence of nonlinear activation functions createse an incentive for features to align with this basis and not get superposed</p>
<ul>
<li><p>if the gains to sparse coding are large enough, this incentive will get overwhelmed</p></li>
</ul>
</li>
<li><p>ways to combat polysemanticity</p>
<ul>
<li><p>activation sparsity</p></li>
<li><p>lateral inhibition / co-occurrence sparsity</p></li>
<li><p>weight sparsity</p></li>
<li><p>superlinear activation functions</p></li>
<li><p>increase neurons per param</p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(\text{SoLU}(x) = x \cdot \text{softmax}(x)\)</span></p>
<ul>
<li><p>adds lateral inhibition, superlinearity, approximate sparsity</p></li>
<li><p>changes GeLU, which is approximately <span class="math notranslate nohighlight">\(\text{sigmoid}(1.7x) \cdot x\)</span></p></li>
<li><p>just changing to SoLU decrease performance, had to add LayerNorm afterwards</p></li>
</ul>
</li>
<li><p>logit lens (<a class="reference external" href="https://www.alignmentforum.org/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens">2020</a>) - apply unembedding matrix to outputs of each transformer layer</p>
<ul>
<li><p>tuned-lens (<a class="reference external" href="https://arxiv.org/abs/2303.08112">belrose…steinhardt, 2023</a>) - train linear model for each layer to decode vocab</p></li>
<li><p>Analyzing Transformers in Embedding Space (<a class="reference external" href="https://arxiv.org/pdf/2209.02535.pdf">dar, …, berant, 2022</a>) - apply unembeddix matrix to weights, etc. to interpret transformers</p></li>
</ul>
</li>
<li><p>Rosetta Neurons: Mining the Common Units in a Model Zoo (dravid, …, efros, shocher, 2023)</p>
<ul>
<li><p>Multimodal Neurons in Pretrained Text-Only Transformers (<a class="reference external" href="https://arxiv.org/pdf/2308.01544.pdf">schwettmann…torralba, 2023</a>)</p></li>
</ul>
</li>
<li><p>The Hydra Effect: Emergent Self-repair in Language Model Computations (<a class="reference external" href="https://arxiv.org/abs/2307.15771">mcgrath…legg, 2023</a>) - ablations atone attention layer of an LLM cause another layer to compensate</p></li>
<li><p>Neurons in Large Language Models: Dead, N-gram, Positional (<a class="reference external" href="https://arxiv.org/pdf/2309.04827.pdf">voita, ferrando, &amp; nalmpantis, 2023</a>)</p></li>
</ul>
</section>
<section id="attention-variants">
<h3><span class="section-number">1.9.3.2. </span>attention variants<a class="headerlink" href="#attention-variants" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Tree Transformer: Integrating Tree Structures into Self-Attention (<a class="reference external" href="https://arxiv.org/pdf/1909.06639.pdf">wang, .., chen, 2019</a>)</p></li>
<li><p>Waveformer: Linear-Time Attention with Forward and Backward Wavelet Transform (<a class="reference external" href="https://arxiv.org/abs/2210.01989">zhuang…shang, 2022</a>)</p></li>
</ul>
</section>
<section id="editing">
<h3><span class="section-number">1.9.3.3. </span>editing<a class="headerlink" href="#editing" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Editing Large Language Models: Problems, Methods, and Opportunities (<a class="reference external" href="https://arxiv.org/pdf/2305.13172.pdf">yao, …, zhang, 2023</a>)</p>
<ul>
<li><p>model-editing = data-efficient alterations to a model</p></li>
</ul>
</li>
<li><p>memory-based</p>
<ul>
<li><p>SERAC: Memory-Based Model Editing at Scale (<a class="reference external" href="https://proceedings.mlr.press/v162/mitchell22a/mitchell22a.pdf">mitchell…manning, finn, 2022</a>)</p>
<ul>
<li><p>keep track of list of edits in external memory and use them as appropriate context at test time (don’t finetune the model)</p></li>
</ul>
</li>
<li><p>T-Patcher (Huang et al., 2023) and CaliNET (Dong et al., 2022) introduce extra trainable parameters into the feed- forward module of PLMs</p></li>
</ul>
</li>
<li><p>weight updates</p>
<ul>
<li><p>Knowledge Neurons in Pretrained Transformers (<a class="reference external" href="https://arxiv.org/abs/2104.08696">dai et al. 2021</a>) - integrated gradients wrt to each neuron in BERT, then selectively udpate these neurons</p></li>
<li><p>ROME: Locating and Editing Factual Associations in GPT (<a class="reference external" href="https://arxiv.org/abs/2202.05262">meng, bau et al. 2022</a> )</p>
<ul>
<li><p><em>localize factual associations</em> - causal intervention for identifying neuron activations that are decisive in a model’s factual predictions</p>
<ul>
<li><p>“causal traces” - run net multiple times, introducing corruptions and then restore states from original non-corrupted forward pass to see which states can restore the original results</p></li>
<li><p>a small number of states contain info that can flip the model from one state to another</p></li>
</ul>
</li>
<li><p><em>change factual associations</em> - modify feedforward weights to update specific factual associations using Rank-One Model Editing (ROME)</p></li>
<li><p>MEMIT: Mass Editing Memory in a Transformer (<a class="reference external" href="https://memit.baulab.info/">meng…, bau, 2022</a>)</p></li>
<li><p>Aging with GRACE: Lifelong Model Editing with Discrete Key-Value Adapters (<a class="reference external" href="https://arxiv.org/abs/2211.11031v3">hartvigsen, …, palangi, …, ghassemi, 2023</a>)</p></li>
</ul>
</li>
<li><p>meta-learning</p>
<ul>
<li><p>KnowledgeEditor: Editing Factual Knowledge in Language Models (<a class="reference external" href="https://arxiv.org/pdf/2104.08164.pdf">de cao, aziz, &amp; titov, 2021</a>) - train a network that takes in input, output, edit and predicts a weight update to the model</p></li>
<li><p>MEND: Fast model editing at scale (<a class="reference external" href="https://arxiv.org/abs/2110.11309">mitchell…finn, manning, 2022</a>)</p>
<ul>
<li><p>a collection of small auxiliary editing networks that use a single desired input-output pair to edit a pre-trained model</p></li>
<li><p>MEND learns to transform the gradient obtained by standard fine-tuning, using a low-rank decomposition of the gradient</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>REMEDI (<a class="reference external" href="https://arxiv.org/pdf/2304.00740.pdf">hernandez, li, &amp; andreas, 2023</a>) and related activation engineering</p>
<ul>
<li><p>get “edit vectors” by obtaining embeddings when passing attributes through LLM</p></li>
<li><p>perform edit by by adding linear transformation of edit vector to prompt embedding</p>
<ul>
<li><p>then, perform generation with latent embedding</p></li>
<li><p>learn linear transformation given a dataset of examples with attributes and desired completions</p>
<ul>
<li><p>(also regularize the model to not change <em>too much</em> on other stuff)</p></li>
</ul>
</li>
</ul>
</li>
<li><p>activation engineering: Steering GPT-2-XL by adding an activation vector (<a class="reference external" href="https://www.alignmentforum.org/posts/5spBue2z2tw4JuDCx/steering-gpt-2-xl-by-adding-an-activation-vector#6__The_Eiffel_Tower_is_in_Rome">turner, …, mini, 2023</a>)</p>
<ul>
<li><p>obtain “steering vector” by embedding a phrase (e.g. <em>love</em>) and adding that vector to the llm embedding during generation</p>
<ul>
<li><p>they only add the embedding for some layers for some tokens</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Extracting Latent Steering Vectors from Pretrained Language Models (<a class="reference external" href="https://arxiv.org/abs/2205.05124">subramani, …, peters, 2022</a>) - find latent vectors via optimization that cause an LLM to output a particular sequence</p>
<ul>
<li><p>then, use these vectors to do things like transfer to new tasks / compute textual similarity</p></li>
</ul>
</li>
</ul>
</li>
<li><p>PURR: Efficiently Editing Language Model Hallucinations by Denoising Language Model Corruptions (<a class="reference external" href="https://drive.google.com/file/d/1CXSUii4w8Y2uj-zLm8zRl63SYh45FaZL/view">chen…sameer singh…kelvin guu, 2023</a>)</p></li>
<li><p>new datasets</p>
<ul>
<li><p>MQUAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions (<a class="reference external" href="https://www.cs.princeton.edu/~zzhong/papers/MQuAKE.pdf">zhong…manning, potts, chen, 2023</a>) - introduces benchmark MQUAKE + method MeLLo, which stores edited facts externally while prompting the language model iteratively to generate answers that are consistent with the edited facts</p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/2305.17553.pdf">COUNTERFACT+ benchmark</a> - checks that edits don’t affect existing info</p></li>
</ul>
</li>
</ul>
</section>
<section id="debugging-interpretation">
<h3><span class="section-number">1.9.3.4. </span>debugging / interpretation<a class="headerlink" href="#debugging-interpretation" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>TalkToModel: Understanding Machine Learning Models With Open Ended Dialogues (<a class="reference external" href="https://arxiv.org/abs/2207.04154">slack…lakkaraju, sameer singh, 2022</a>) - natural language interface to query model (by converting to commands such as filtering the data / calculating importance)</p>
<ul>
<li><p>Rethinking Explainability as a Dialogue: A Practitioner’s Perspective (<a class="reference external" href="https://arxiv.org/abs/2202.01875">lakkaraju, slack, …, sameer singh, 2022</a>) - interviews with high-stakes users suggest they would like to be able to interact with systems via dialog</p></li>
</ul>
</li>
<li><p>The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning (<a class="reference external" href="https://arxiv.org/abs/2205.03401?context=cs">ye &amp; durrett, 2022</a>)</p></li>
<li><p>AdaTest: Adaptive Testing and Debugging of NLP Models (<a class="reference external" href="https://aclanthology.org/2022.acl-long.230/">ribeiro &amp; lundberg, 2022</a>)</p>
<ul>
<li><p>goal: easily specify, discover, and fix undesirable behaviors in an NLP model</p></li>
<li><p>2-step iterative algorithm</p>
<ol class="simple">
<li><p>LLM generates many tests targeting the model’s failures</p>
<ul>
<li><p>example of a test: <code class="docutils literal notranslate"><span class="pre">f(“I</span> <span class="pre">am</span> <span class="pre">a</span> <span class="pre">black</span> <span class="pre">woman”)</span> <span class="pre">≠</span> <span class="pre">neg</span></code></p></li>
<li><p>user selects and organizes the tests and reprompts the LLM to find more</p></li>
</ul>
</li>
<li><p>User fixes the tests (e.g. via finetuning)</p></li>
</ol>
</li>
<li><p>Checklist <a class="reference external" href="https://arxiv.org/abs/2005.04118">Beyond Accuracy: Behavioral Testing of NLP models with CheckList</a> (ribeiro…sameer singh, 2020)</p>
<ul>
<li><p>matrix of general linguistic capabilities + test types</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Fixing Model Bugs with Natural Language Patches (<a class="reference external" href="https://openreview.net/forum?id=B6wzhbPhsZ9">murty, manning, lundberg, &amp; ribeiro 2022</a>)</p>
<ul>
<li><p>specify patches with natural language rather than hard rule, allowing them to better handle text</p></li>
<li><p>finetune a model to combine original model output with output from a patch-conditioned interpreter head</p></li>
</ul>
</li>
<li><p>Aug-imodels: Augmenting Interpretable Models with LLMs during Training (<a class="reference external" href="https://arxiv.org/abs/2209.11799">singh, askari, caruana, &amp; gao, 2023</a>)</p></li>
</ul>
</section>
<section id="symbolic-reasoning">
<h3><span class="section-number">1.9.3.5. </span>symbolic reasoning<a class="headerlink" href="#symbolic-reasoning" title="Permalink to this headline">#</a></h3>
<p><em>See also notes on <a class="reference external" href="https://csinva.io/notes/research_ovws/ovw_comp_neuro.html">📌 comp neuro</a>.</em></p>
<ul class="simple">
<li><p>GPT-3 <a class="reference external" href="https://arxiv.org/abs/2205.11916">Large Language Models are Zero-Shot Reasoners</a> - simply adding “Let’s think step by step” before each answer increases the accuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7% with GPT-3</p></li>
<li><p><a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8491571/">Compositional processing emerges in neural networks solving math problems</a> (russin, roland fernandez, …, smolensky, gao, 2021)</p></li>
<li><p>Modular Deep Learning (<a class="reference external" href="https://arxiv.org/pdf/2302.11529.pdf">pfeiffer, ruder, .., ponti, 2023)</a> - overview of different modular architectures</p></li>
<li><p>neurocompositional computing (<a class="reference external" href="https://arxiv.org/abs/2205.01128">smolensky…gao, 2022</a>)</p>
<ul>
<li><p>longer tutorial (<a class="reference external" href="https://www.microsoft.com/en-us/research/uploads/prod/2022/04/Neurocompositional_computing__tutorial.pdf">smolensky, …, gao, 2022</a>)</p></li>
<li><p><em>central paradox of cognition</em> is that brain both uses continuous neural symbols but is compositional (<a class="reference external" href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.4352&amp;rep=rep1&amp;type=pdf">smolensky et al. 1992</a>)</p>
<ul>
<li><p>Compositionality</p></li>
<li><p>Continuity - the encoding and processing of information is formalized with real numbers that vary continuously</p></li>
</ul>
</li>
<li><p>3 challenges</p>
<ul>
<li><p>compositional generalization</p></li>
<li><p>data efficiency</p></li>
<li><p>comprehensibility</p></li>
</ul>
</li>
<li><p>solution - NECST: Neurally-Encoded Compositionally-Structured Tensor computing (<a class="reference external" href="https://psycnet.apa.org/record/2006-07970-000">smolensky &amp; legendre, 2006</a>) - basically leverages TPR</p>
<ul>
<li><p>TPR roles and fillers can both be made continuous</p></li>
</ul>
</li>
<li><p>neural space vs symbolic space (many different things (e.g. sentences) can mean the same thing)</p>
<ul>
<li><p>word vectors can be thought of as “soft symbols”</p></li>
</ul>
</li>
<li><p>want to move from symbolic repr. to neural repr. while keeping interpretability</p>
<ul>
<li><p>system should output intermediate steps in addition to answer</p></li>
<li><p>thinking fast (system 1: fast, intuitive) + slow (system 2: slower, logical, derivative)</p></li>
</ul>
</li>
<li><p>concrete proposals</p>
<ul>
<li><p>transformer activation vector should encode graph of flow through the network</p>
<ul>
<li><p>ex. task: regurgitate a sequence</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>TPR: Tensor product variable binding and the representation of symbolic structures in connectionist systems (<a class="reference external" href="https://www.sciencedirect.com/science/article/abs/pii/000437029090007M?via%3Dihub">paul smolensky, 1990</a>) - activation patterns are “symbols” and internal structure allows them to be processed like symbols</p>
<ul>
<li><p>tensor product representation = TPR</p></li>
<li><p><a class="reference external" href="https://www.mit.edu/~jda/teaching/6.884/slides/oct_02.pdf">TPR slides</a></p></li>
<li><p>TPR of a structure is the sum of the TPR of its constituents</p>
<ul>
<li><p>tensor product operation allows constituents to be uniquely identified, even after the sum (if roles are linearly independent)</p></li>
</ul>
</li>
<li><p><strong>filler</strong> - one vector that embeds the content of the constituent</p></li>
<li><p><strong>role</strong> - second vector that embeds the structural role it fills</p></li>
</ul>
</li>
<li><p>NECSTransformer: <a class="reference external" href="https://www.microsoft.com/en-us/research/publication/enhancing-the-transformer-with-explicit-relational-encoding-for-math-problem-solving/">Enhancing the Transformer with Explicit Relational Encoding for Math Problem Solving</a> (schlag, …, gao, 2019)</p></li>
<li><p>TP-attention</p></li>
<li><p>beat SOAon free-form math word-problems</p></li>
<li><p>in addition to K, Q, V, also add a role-vector</p>
<ul>
<li><p>do element-wise multiplication of outputted vector with role-vector</p></li>
</ul>
</li>
<li><p>TPR built as tensor product of 2 vectors:</p>
<ul>
<li><p>filler - the vector returned by attention</p>
<ul>
<li><p>ex. one head learns “second-argument-of”</p></li>
</ul>
</li>
<li><p>role - a relation conceptually labeling an edge of the attention graph</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.microsoft.com/en-us/research/publication/natural-to-formal-language-generation-using-tensor-product-representations/">TP-N2F: Tensor Product Representation for Natural To Formal Language Generation - Microsoft Research</a> (chen…gao, 2019)</p></li>
<li><p>Logical Transformers: Infusing Logical Structures into Pre-Trained Language Models (<a class="reference external" href="https://aclanthology.org/2023.findings-acl.111/">wang, huang, …, gao, 2023</a>) - use logical model to alter embeddings before feeding to LLM</p></li>
</ul>
</section>
<section id="adaptation-transfer">
<h3><span class="section-number">1.9.3.6. </span>adaptation / transfer<a class="headerlink" href="#adaptation-transfer" title="Permalink to this headline">#</a></h3>
<p><em>These are transformer-specific. For more general notes, see <a class="reference external" href="https://csinva.io/notes/research_ovws/ovw_transfer_learning.html">📌 transfer learning</a> or <a class="reference external" href="https://csinva.io/notes/research_ovws/ovw_transfer_learning.html">📌 uncertainty</a>.</em> Most of these approaches can be combined with metalearning.</p>
<ul class="simple">
<li><p>finetuning</p>
<ul>
<li><p>finetune all DNN params</p></li>
<li><p>finetune linear layer on activations</p>
<ul>
<li><p>standard - train linear model on the embedding of the first token (usually an added <code class="docutils literal notranslate"><span class="pre">[CLS]</span></code> token) (<a class="reference external" href="https://aclanthology.org/N18-1202/">peters et al. 2018</a>)</p></li>
<li><p>finetune linear model on all the activations</p>
<ul>
<li><p>e.g. <a class="reference external" href="https://arxiv.org/abs/2201.03529">evci, et al. 2022</a> - learn linear layer (using group-lasso) on features extracted from all layers</p></li>
</ul>
</li>
</ul>
</li>
<li><p>finetune specific DNN params (e.g. just the bias terms)</p>
<ul>
<li><p>Cutting Down on Prompts and Parameters (<a class="reference external" href="https://arxiv.org/abs/2106.13353">logan…sameer singh, riedel, 2021</a>) - finetune only the bias terms; works even with null prompts</p></li>
<li><p>BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models (<a class="reference external" href="https://arxiv.org/abs/2106.10199">zaken, ravfogel, &amp; goldberg, 2021</a>) - finetune only bias terms</p></li>
</ul>
</li>
</ul>
</li>
<li><p>adapter - finetune lightweight layers on top of pre-trained layers (between finetuning all layers, and just finetuning a new layer)</p>
<ul>
<li><p>add some new layers and retrain some specific things (all human choices)</p></li>
<li><p>side-tuning (<a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-030-58580-8_41">zhang, sax…malik, 2020</a>) - train a “side” network that is fused with the pretrained model via summation</p></li>
<li><p>Combining Modular Skills in Multitask Learning (<a class="reference external" href="https://arxiv.org/pdf/2202.13914.pdf">ponti, sordoni, bengio, &amp; reddy, 2022</a>) - learn adaptor with disentangled inventory of skills</p></li>
<li><p><a class="reference external" href="http://proceedings.mlr.press/v97/houlsby19a.html">Parameter-Efficient Transfer Learning for NLP</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2007.07779">AdapterHub: A Framework for Adapting Transformers</a></p></li>
</ul>
</li>
<li><p>vaguely similar to adapter</p>
<ul>
<li><p>LoRA</p></li>
<li><p>QLoRA: Efficient Finetuning of Quantized LLMs (<a class="reference external" href="https://arxiv.org/abs/2305.14314">dettmers, …, zettlemoyer, 2023</a>)</p></li>
<li><p>TOAST (<a class="reference external" href="https://arxiv.org/pdf/2305.15542.pdf">shi, …, darrel, xin wang, 2023</a>) - use top-down attention steering for efficient finetuning</p></li>
</ul>
</li>
<li><p>predict a mask</p>
<ul>
<li><p>ablate some model weights by training a binary mask over model parameters (Zhao et al., 2020; Radiya-Dixit and Wang, 2020)</p></li>
<li><p>predict mask over attention heads</p></li>
</ul>
</li>
<li><p>prompting = few-shot learning = priming = in-context learning (starts with GPT)</p>
<ul>
<li><p>prompting without changing any model parameters</p>
<ul>
<li><p>limitation: can’t exploit sets longer than the training window</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2110.15943">MetaICL: Learning to Learn In Context</a> (min et al. 2022) - tune LLM to do in-context learning on a large set of training tasks (few-show prompting and training time and at test-time)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2209.00647">Visual Prompting via Image Inpainting</a> (bar…darrell, globerson, efros, 2022)</p></li>
<li><p>PatternExploiting Training (PET) – Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference (<a class="reference external" href="https://aclanthology.org/2021.eacl-main.20.pdf">schick &amp; schutze, 2021</a>)</p>
<ul>
<li><p><strong>cloze questions</strong> - same as masked language modeling: task is to replace some missing words</p></li>
<li><p>use cloze-question templates (e.g. it was “good” or “bad”) to get soft labels for unlabeled data and then finetune on theses</p></li>
</ul>
</li>
</ul>
</li>
<li><p>prompt-tuning (also see next section on autoprompting)</p>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/abs/2205.11961">Attentional Mixtures of Soft Prompt Tuning for Parameter-efficient Multi-task Knowledge Sharing</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2207.08408">STT: Soft Template Tuning for Few-Shot Adaptation</a></p></li>
<li><p>Mixture of Soft Prompts for Controllable Data Generation (<a class="reference external" href="https://arxiv.org/abs/2303.01580">chen, … yu, 203</a>) - LLMs as Synthetic Data Generators for Training Smaller Models</p></li>
</ul>
</li>
</ul>
<p><strong>mt-dnn line of work</strong></p>
<ul class="simple">
<li><p>Multi-Task Deep Neural Networks for Natural Language Understanding (<a class="reference external" href="https://aclweb.org/anthology/papers/P/P19/P19-1441/">xiaodong liu … gao 2019</a>) - multi-task learning on the 9 glue tasks (first layers are shared, then some task-specific layers at top)</p></li>
<li><p>RAdam: On the Variance of the Adaptive Learning Rate and Beyond (<a class="reference external" href="https://openreview.net/pdf?id=rkgz2aEKDr">liyuan liu…gao, han, 2020</a>)</p>
<ul>
<li><p>usually need to do learning-rate warmup when trainin (e.g. with Adam)</p></li>
<li><p>RAdam = add a term to rectify the variance of the adaptive learning rate in Adam</p></li>
</ul>
</li>
<li><p>SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization (<a class="reference external" href="https://aclanthology.org/2020.acl-main.197/">jiang…gao, zhao, 2020</a>)</p>
<ol class="simple">
<li><p>Smoothness-inducing regularization, which effectively manages the complexity of the model</p></li>
<li><p>Bregman proximal point optimization to prevent aggressive updating</p></li>
</ol>
</li>
<li><p>Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding (<a class="reference external" href="https://aclanthology.org/2020.acl-demos.16/">xiaodong liu…gao, 2020</a>)</p></li>
<li><p>Posterior Differential Regularization with f-divergence for Improving Model Robustness (<a class="reference external" href="https://aclanthology.org/2021.naacl-main.85/">hao cheng, …, gao 2021</a>)</p>
<ul>
<li><p>regularize model posterior difference between clean + noisy inputs (e.g. adversarially attacked inputs)</p></li>
</ul>
</li>
</ul>
<p><strong>comparing different tasks</strong></p>
<ul class="simple">
<li><p>Task2Vec: Task Embedding for Meta-Learning (<a class="reference external" href="https://openaccess.thecvf.com/content_ICCV_2019/html/Achille_Task2Vec_Task_Embedding_for_Meta-Learning_ICCV_2019_paper.html">achille, …, soatto, perona, 2019</a>) - summarize each task as a vector, by taking diagonal of fisher info matrix (derivative of network output wrt to parameters) - clusters similar tasks</p></li>
<li><p>Efficiently Tuned Parameters are Task Embeddings (<a class="reference external" href="https://arxiv.org/abs/2210.11705">zhou…mcauley, 2022</a>)</p></li>
<li><p>Editing Models with Task Arithmetic (<a class="reference external" href="https://arxiv.org/abs/2212.04089">ilharco, ribeiro, …, farhadi, 2022</a>) - task vector is model weights after task finetuning - model weights before finetuning</p>
<ul>
<li><p>can use this direction to alter model behavior</p></li>
</ul>
</li>
<li><p>Overcoming Catastrophic Forgetting in Zero-Shot Cross-Lingual Generation (<a class="reference external" href="https://arxiv.org/abs/2205.12647">vu….constant, 2022</a>) - train with prompts of some (language translation, task) pairs and show that they can generalize to new (language, task) pairs</p></li>
</ul>
</section>
<section id="model-merging-mixture-of-experts-moe-routing">
<h3><span class="section-number">1.9.3.7. </span>model merging / mixture of experts (MoE) / routing<a class="headerlink" href="#model-merging-mixture-of-experts-moe-routing" title="Permalink to this headline">#</a></h3>
<p>mixture of experts models have become popular because of the need for (1) fast speed / low memory at test time while still (2) having a large model during training</p>
<ul class="simple">
<li><p>note: nowadays often the “experts” are different MLPs following the self-attention layers</p></li>
<li><p>A Review of Sparse Expert Models in Deep Learning (<a class="reference external" href="https://arxiv.org/abs/2209.01667">fedus, jeff dean, zoph, 2022</a>)</p>
<ul>
<li><p>sparsity decouples the parameter count from the compute per example allowing for extremely large, but efficient models</p></li>
<li><p>routing algorithm - determines where to send examples</p>
<ul>
<li><p>discreteness makes it difficult</p>
<ul>
<li><p>some works use RL to learn routing</p></li>
<li><p>standard approach uses gumbel-softmax</p></li>
<li><p>usually get matrix of similarities between input tokens and experts and route based on these</p>
<ul>
<li><p>sometimes route to topk experts rather than top1</p></li>
</ul>
</li>
</ul>
</li>
<li><p>load balancing - usually add an auxiliary loss to encourage equal tokens being sent to different experts</p></li>
</ul>
</li>
</ul>
</li>
<li><p>non-specialized experts</p>
<ul>
<li><p>Early versions (<a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/6797059">Jacobs, michael jordan, nowlan, &amp; hinton, 1991</a>) had independent feed-forward networks serving as experts</p></li>
<li><p>Sparsely-gated MOE layer (<a class="reference external" href="https://arxiv.org/abs/1701.06538">Shazeer…quoc le, hinton, dean, 2017</a>) have been studied with token-based routing with backprop</p></li>
<li><p>replace FFN in transformers with expert layers</p>
<ul>
<li><p>GShard <a class="reference external" href="https://arxiv.org/abs/2006.16668">Lepikhin et al. (2021)</a>, which appplies this concept to machine translation</p></li>
<li><p>Switch transformers (<a class="reference external" href="https://www.jmlr.org/papers/volume23/21-0998/21-0998.pdf">Fedus et al. (2022)</a>) simplifies the architecture to activation of only one expert per layer</p></li>
</ul>
</li>
<li><p>BASE Layers <a class="reference external" href="https://proceedings.mlr.press/v139/lewis21a.html">Lewis et al. (2021)</a> - find an alternative approach to routing by formulating it as a linear assignment problem</p></li>
<li><p>Hash layers <a class="reference external" href="https://arxiv.org/abs/2106.04426">Roller et al. (2021)</a> use a fixed hash as the gating function</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.sscardapane.it/assets/files/nnds2022/Lecture_8_Dynamic_NNs.pdf">routing notes</a> - make hard decision but still want to learn probabilities</p>
<ul>
<li><p>straight-through estimator (STE) - take the argmax during the forward pass, while considering the orig- inal probabilities in the backward pass</p>
<ul>
<li><p>highly biased</p></li>
</ul>
</li>
<li><p>gumbel-softmax- allows for better sampling</p></li>
</ul>
</li>
<li><p>specialized experts as fully independent models (sometimes for multi-task learning)</p>
<ul>
<li><p>DEmix Layers <a class="reference external" href="https://arxiv.org/abs/2108.05036">Gururangan et al.</a> (2022) –  DEMix layers – placed in the feedforward layers of the Transformer – contain experts which specialize on specific domains. Routing at train time is determined only by the domain label, but all experts are activated at inference time and mixed according to weights estimated from a validation set</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2204.07689">Sparsely Activated Mixture-of-Experts are Robust Multi-Task Learners</a> (gupta…awadallah, gao, 2022) - use task description to improve routing</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2205.06266">Pfeiffer et al. (2022)</a> - multilingual expert model with language-specific routing</p></li>
<li><p>task-level MoE <a class="reference external" href="https://arxiv.org/abs/2110.03742">Kudugunta et al. (2021</a>) – multi-task expert model with task-specific routing</p></li>
<li><p>scaling up</p>
<ul>
<li><p>OPT-MOE (<a class="reference external" href="https://arxiv.org/abs/2112.10684">artetxe et al. 2021</a>)</p></li>
<li><p>AutoMoE (<a class="reference external" href="https://arxiv.org/abs/2210.07535">jawahar, mukherjee, liu…gao, 2022</a>)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2005.00147">Interpretable entity representations through large-scale typing</a> (onoe &amp; durrett, 2020) - embedding is interpretable predictions for different entities/</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2208.02813">Towards Understanding Mixture of Experts in Deep Learning</a> (chen…gu, li, 2022)</p></li>
<li><p>model merging (some of these are non-transformer papers) = combine different models that have the same architecture</p>
<ul>
<li><p>model soups (<a class="reference external" href="https://proceedings.mlr.press/v162/wortsman22a.html">wortsman…schmidt, 20221</a>) - average weights of finetuned models</p>
<ul>
<li><p>snapshot ensembles - average different checkpoints during training (<a class="reference external" href="https://arxiv.org/abs/1704.00109">huang et al. 2017</a>)</p></li>
<li><p>stochastic weight averaging (<a class="reference external" href="https://arxiv.org/abs/1803.05407v3">izmailov, …, wilson, 2019</a>) - average multiple checkpoints during training</p></li>
<li><p>batch ensemble (<a class="reference external" href="https://arxiv.org/pdf/2002.06715.pdf">wen et al. 2020</a>) - have several rank-1 keys that index different weights hidden within one neural net</p></li>
</ul>
</li>
<li><p>ELMS – Branch-Train-Merge (<a class="reference external" href="https://arxiv.org/abs/2208.03306">li et al. 2022</a>)</p>
<ul>
<li><p>parallel language model of smaller expert LMs</p></li>
<li><p>each can be added/removed, ensembled, or parameter-averaged at any time for efficient scaling and rapid customization</p></li>
<li><p>improves perplexities, when controlling for training cost</p>
<ul>
<li><p>require expert domain specialization</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Merging Models with Fisher-Weighted Averaging (<a class="reference external" href="https://arxiv.org/abs/2111.09832">matena &amp; raffel, 2022</a>) - merge models with same architecture with particular weights</p>
<ul>
<li><p>An Empirical Study of Multimodal Model Merging (<a class="reference external" href="https://arxiv.org/abs/2304.14933">sung…wang</a>) - merge a separately trained vision &amp; language model and get a multiomodal model</p></li>
</ul>
</li>
<li><p>TIES: Resolving Interference When Merging Models (<a class="reference external" href="https://arxiv.org/abs/2306.01708">yadav…raffel, bansal, 2023</a>) - empirical heuristics for merging model weights specific to tasks, e.g. vote on signs of parameters</p></li>
</ul>
</li>
<li><p>fit many models into one</p>
<ul>
<li><p>superposition of many models into one (<a class="reference external" href="https://proceedings.neurips.cc/paper/2019/hash/4c7a167bb329bd92580a99ce422d6fa6-Abstract.html">cheung…olshausen, 2019</a>) - both during training/testing models are indexed via a high-dim key for each task</p></li>
<li><p>supermasks in superposition (<a class="reference external" href="https://proceedings.neurips.cc/paper/2020/hash/ad1f8bb9b51f023cdc80cf94bb615aa9-Abstract.html">wortsman, …, yosinski, farhadi, 2020</a>) - randomly fixed based net + for each task finds subnet that chieves good performance</p>
<ul>
<li><p>if task identity not given, correct subnet inferred by minimizing output entropy</p></li>
</ul>
</li>
<li><p>Git Re-Basin: Merging Models modulo Permutation Symmetries (<a class="reference external" href="https://arxiv.org/abs/2209.04836">ainsworth, hayase, &amp; srinivasa, 2022</a>) - algo to merge models even when they haven’t been pretrained together</p></li>
</ul>
</li>
<li><p>early exit - popular way to speed up inference</p>
<ul>
<li><p>Multi-exit vision transformer for dynamic inference (<a class="reference external" href="https://arxiv.org/abs/2106.15183">Bakhtiarnia, A., Zhang, Q. and Iosifidis, A., 2021</a>)</p>
<ul>
<li><p>early layers have large activation map so early exist classifier must be complex</p></li>
<li><p>solution: ViT class token allows early-exit classifier to have constant complexity</p></li>
</ul>
</li>
<li><p>DeeBERT: Dynamic early exiting for accelerating BERT inference (<a class="reference external" href="https://arxiv.org/abs/2004.12993">xin…lin, 2020</a>)</p></li>
</ul>
</li>
</ul>
</section>
<section id="embeddings">
<h3><span class="section-number">1.9.3.8. </span>embeddings<a class="headerlink" href="#embeddings" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Instructor: One Embedder, Any Task: Instruction-Finetuned Text Embeddings (<a class="reference external" href="https://instructor-embedding.github.io">su, …, smith, zettlemoyer, yu, 2022</a>) - embedding is contextualized to eaach task</p></li>
<li><p>Text Embeddings Reveal (Almost) As Much As Text (<a class="reference external" href="https://openreview.net/pdf?id=wK7wUdiM5g0">2023</a>)</p></li>
<li><p>Explaining embeddings</p>
<ul>
<li><p>Computer-vision focused</p>
<ul>
<li><p>Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning (<a class="reference external" href="https://arxiv.org/abs/2103.00370">hamilton, lundberg…freeman, 2021</a>) - add in “second-order” methods that look at similarities between different image features in the 2 images being compared</p></li>
<li><p>Why do These Match? Explaining the Behavior of Image Similarity Models (<a class="reference external" href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123560630.pdf">plummer…saenko, forsyth, 2020</a>) - generate saliency map + with an attribute based on the salient region</p></li>
<li><p>Towards Visually Explaining Similarity Models (<a class="reference external" href="https://arxiv.org/abs/2008.06035">zheng…wu, 2020</a>) - similarity of cnn embeddings</p></li>
</ul>
</li>
<li><p>Explaining similarity with different outputs</p>
<ul>
<li><p>Analogies and Feature Attributions for Model Agnostic Explanation of Similarity Learners (<a class="reference external" href="https://arxiv.org/pdf/2202.01153.pdf">ramamurthy…tariq, 2022</a>) - returned explanation is an analogy (pair from the training set) rather than a saliency map</p></li>
<li><p>Sim2Word: Explaining Similarity with Representative Attribute Words via Counterfactual Explanations (<a class="reference external" href="https://dl.acm.org/doi/full/10.1145/3563039">chen…cao, 2023</a>) - give both saliency map + counterfactual explanation</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="pruning">
<h3><span class="section-number">1.9.3.9. </span>pruning<a class="headerlink" href="#pruning" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot (<a class="reference external" href="https://arxiv.org/abs/2301.00774">frantar &amp; alistarh, 2023</a>) - prune GPT-style models to atleast 50% sparsity in one-shot, without any retraining, at minimal loss of accuracy</p></li>
<li><p>Cramming: Training a Language Model on a Single GPU in One Day (<a class="reference external" href="https://arxiv.org/abs/2212.14034">geiping &amp; goldstein, 2022</a>) - tricks for training BERT</p></li>
</ul>
</section>
</section>
<section id="applications">
<h2><span class="section-number">1.9.4. </span>applications<a class="headerlink" href="#applications" title="Permalink to this headline">#</a></h2>
<section id="dataset-module-explanation">
<h3><span class="section-number">1.9.4.1. </span>dataset / module explanation<a class="headerlink" href="#dataset-module-explanation" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>dataset explanation</p>
<ul>
<li><p>iPrompt: Explaining Patterns in Data with Language Models via Interpretable Autoprompting (<a class="reference external" href="https://arxiv.org/abs/2210.01848">singh, morris, …gao, 2022</a> ) - prompting approach</p></li>
<li><p>Instruction Induction: From Few Examples to Natural Language Task Descriptions (<a class="reference external" href="https://arxiv.org/abs/2205.10782">honovich…bowman, levy 2022</a>) - directly query model with prompt to search for task description</p></li>
<li><p>D3: Describing Differences between Text Distributions with Natural Language (<a class="reference external" href="https://arxiv.org/abs/2201.12323">zhong, snell, klein, &amp; steinhardt, 2022</a>) - finetune an LLM to directly describe difference between 2 text distrs</p>
<ul>
<li><p>D5: Goal Driven Discovery of Distributional Differences via Language Descriptions (<a class="reference external" href="https://arxiv.org/abs/2302.14233">zhong, zhang, …, klein, &amp; steinhardt, 2023</a>) - add dataset-specific prompt + evaluation on larger set of 675 datasets</p></li>
<li><p>technically this is just learning a classifier, where the classifier is a natural-language string</p></li>
<li><p>method</p>
<ul>
<li><p>proposer network generates hypotheses</p></li>
<li><p>verifier networks looks at all samples in the dataset (since proposer couldn’t fit them all in context) and returns how accurate the hypotheses were</p></li>
<li><p>some tricks</p>
<ul>
<li><p>select samples which are “representative” of a class by predicting with another LLM</p></li>
<li><p>have a pool of 302 manual hypotheses they usefor seeding</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Goal-Driven Explainable Clustering via Language Descriptions (<a class="reference external" href="https://arxiv.org/abs/2305.13749">wang…, zhong, 2023</a>)</p>
<ul>
<li><p>ClusterLLM: Large Language Models as a Guide for Text Clustering (<a class="reference external" href="https://arxiv.org/abs/2305.14871">zhang…shang, 2023</a>)</p></li>
<li><p>LLMs4OL: Large Language Models for Ontology Learning (<a class="reference external" href="https://arxiv.org/pdf/2307.16648.pdf">giglou et al. 2023</a>) - use prompting to construct ontologies</p></li>
<li><p>Towards Ontology Construction with Language Models (<a class="reference external" href="https://arxiv.org/abs/2309.09898">funk…lutz, 2023</a>)</p></li>
</ul>
</li>
<li><p>Mass-Producing Failures of Multimodal Systems with Language Models (<a class="reference external" href="https://arxiv.org/abs/2306.12105">tong, jones, &amp; steinhardt, 2023</a>)</p></li>
</ul>
</li>
<li><p>GSCLIP : A Framework for Explaining Distribution Shifts in Natural Language (<a class="reference external" href="https://arxiv.org/abs/2206.15007">zhu…james zou, 2022</a>) - automatically explain dataset-level distribution shifts (in image datasets) with natural language</p></li>
<li><p>MaNtLE: Model-agnostic Natural Language Explainer (<a class="reference external" href="https://arxiv.org/pdf/2305.12995.pdf">menon, zaman, &amp; srivastava, 2023</a>) - train model to generate explanations on simple tables (they do this for classifier outputs but could easily do it directly for data labels)</p></li>
<li><p>Large Language Models for Automated Open-domain Scientific Hypotheses Discovery (<a class="reference external" href="https://arxiv.org/abs/2309.02726">yang…cambria, 2023</a>)</p></li>
</ul>
</li>
<li><p>module explanation in natural language</p>
<ul>
<li><p>Explaining black box text modules in natural language with language models (<a class="reference external" href="https://arxiv.org/abs/2305.09863">singh, hsu, …, gao, 2023</a>)</p></li>
<li><p>Language models can explain neurons in language models (<a class="reference external" href="https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html">bills, cammarata, …saunders, 2023, openai</a>)</p>
<ul>
<li><p>goal: explain a neuron</p>
<ul>
<li><p>step 1: summarize (token, activation) pairs into an explanation</p></li>
<li><p>step 2: create simulated neuron that outputs activations given tokens</p></li>
<li><p>step 3: check correlation of simulated neuron outputs with real neuron outputs</p></li>
</ul>
</li>
<li><p>their <a class="reference external" href="https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html">unigram baseline</a> summarizes top unigrams into a string</p></li>
<li><p>they use synthetic generated data to revise the explanation</p></li>
<li><p>they also do some recovery tests on “neuron puzzles”</p></li>
</ul>
</li>
<li><p>MILAN: Natural Language Descriptions of Deep Visual Features (<a class="reference external" href="https://openreview.net/forum?id=NudBMY-tzDr">hernandez…david bau…torallba, andreas, 2022</a>) - given a neuron, generates a natural-language string that maximizes pointwise mutual information with the image regions in which the neuron is active</p>
<ul>
<li><p>Scale Alone Does not Improve Mechanistic Interpretability in Vision Models (<a class="reference external" href="https://arxiv.org/abs/2307.05471">zimmermann, klein, &amp; brendel, 2023</a>) - perform human eval of interpretability of different units (show human top-activating patches and ask them to decide which of 2 patches will be top-activating)</p></li>
</ul>
</li>
<li><p>A Function Interpretation Benchmark for Evaluating Interpretability Methods (<a class="reference external" href="https://arxiv.org/abs/2309.03886">schwettmann, …, andreas, bau, &amp; torralba, 2023</a>)</p></li>
</ul>
</li>
</ul>
</section>
<section id="learning-algorithms">
<h3><span class="section-number">1.9.4.2. </span>learning algorithms<a class="headerlink" href="#learning-algorithms" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Empirical results</p>
<ul>
<li><p>Discovering faster matrix multiplication algorithms with reinforcement learning (<a class="reference external" href="https://www.nature.com/articles/s41586-022-05172-4">deepmind, 2022</a>)</p></li>
<li><p>Faster sorting algorithms discovered using deep reinforcement learning (<a class="reference external" href="https://www.nature.com/articles/s41586-023-06004-9">deepmind, 2023</a>)</p></li>
<li><p>Nuclear fusion control (<a class="reference external" href="https://www.nature.com/articles/s41586-021-04301-9">deepmind, 2022</a>)</p></li>
</ul>
</li>
<li><p>What Can Transformers Learn In-Context? A Case Study of Simple Function Classes (<a class="reference external" href="https://arxiv.org/abs/2208.01066">garg, tsipras, liang, &amp; valiant, 2022</a>) - models can succesfully metalearn functions like OLS</p>
<ul>
<li><p>e.g. during training, learn inputs-outputs from different linear functions</p></li>
<li><p>during testing, have to predict outputs for inputs from a different linear function</p></li>
<li><p>also test on slightly harder functions, like decision trees and 2-layer nets</p></li>
</ul>
</li>
<li><p>Learning a (sparse) linear model</p>
<ul>
<li><p>The contextual lasso: Sparse linear models via deep neural networks (<a class="reference external" href="https://arxiv.org/pdf/2302.00878.pdf">thompson, …, kohn, 2023</a>) - very rough results…</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2305.13072">Breaking the Paradox of Explainable Deep Learning</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2209.11799">Aug-imodels</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2211.15661">What learning algorithm is in-context learning? Investigations with linear models</a> - investigate prompting through synthetic experiments with transformers trained for linear regression</p>
<ul>
<li><p>Transformers as Algorithms: Generalization and Implicit Model Selection in In-context Learning (<a class="reference external" href="https://arxiv.org/pdf/2301.07067.pdf">li, …, oymak, 2023</a>) - generalization bounds for in-context learning when the input prompt is (1) a sequence of i.i.d. (input, label) pairs or (2) a trajectory arising from a dynamical system</p></li>
<li><p>Trained Transformers Learn Linear Models In-Context (<a class="reference external" href="https://arxiv.org/pdf/2306.09927.pdf">zhang, frei, &amp; bartlett, 2023</a>)</p></li>
<li><p>One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention (<a class="reference external" href="https://arxiv.org/pdf/2307.03576.pdf">Mahankali, Hashimoto, Ma, 23</a>)</p>
<ul>
<li><p>math analysis for: icl can do gradient decent on linear regression</p></li>
</ul>
</li>
<li><p>Pretraining task diversity and the emergence of non-Bayesian in-context learning for regression (<span class="xref myst">raventos, … ,ganguli, 2023</span>)</p></li>
</ul>
</li>
<li><p>Teaching Algorithmic Reasoning via In-context Learning (<a class="reference external" href="https://arxiv.org/abs/2211.09066">zhou…sedghi, 2022</a>)</p></li>
<li><p>Looped Transformers as Programmable Computers (<a class="reference external" href="https://arxiv.org/abs/2301.13196">giannou, …, jason lee, papailiopoulos, 2023</a> - use transformers as universal computers by programming them with specific weights</p></li>
<li><p>Learning mathematical problems (<a class="reference external" href="https://scholar.google.com/citations?hl=en&amp;user=1tMnd-4AAAAJ&amp;view_op=list_works&amp;sortby=pubdate">francois charton</a>)</p></li>
<li><p>Negative results</p>
<ul>
<li><p>Faith and Fate: Limits of Transformers on Compositionality (<a class="reference external" href="https://arxiv.org/abs/2305.18654">dziri…choi, 2023</a>) - LLMs can’t (easily) be trained well for multiplication (and similar tasks)</p></li>
</ul>
</li>
<li><p>Theory (don’t directly predict algorithm)</p>
<ul>
<li><p>Meta-learning for Mixed Linear Regression (<a class="reference external" href="https://proceedings.mlr.press/v119/kong20a.html">kong…kakade, oh, 2020</a>) - generalization for linear regression based on which linear tasks were seen before</p></li>
</ul>
</li>
</ul>
</section>
<section id="cool-tasks">
<h3><span class="section-number">1.9.4.3. </span>cool tasks<a class="headerlink" href="#cool-tasks" title="Permalink to this headline">#</a></h3>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/abs/2206.15474">Forecasting Future World Events with Neural Networks</a> (zou…hendrycks, 2022) - takes tasks from metaculus</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2208.11857">Shortcut Learning of Large Language Models in Natural Language Understanding: A Survey</a> (du et al. 2022)</p></li>
<li><p>Neurosymbolic Programming for Science (<a class="reference external" href="https://arxiv.org/abs/2210.05050">sun…costilla-reyes, 2022</a>)</p></li>
<li><p>Discovering New Interpretable Conservation Laws as Sparse Invariants (<a class="reference external" href="https://arxiv.org/abs/2305.19525">liu…tegmark, 2023</a>) - does not use transformers</p></li>
<li><p>evaluation without groundtruth</p>
<ul class="simple">
<li><p>Evaluating Superhuman Models with Consistency Checks (<a class="reference external" href="https://arxiv.org/abs/2306.09983">fluri, …, tramer, 2023</a>)</p></li>
</ul>
</li>
<li><p>Learning from learning machines: a new generation of AI technology to meet the needs of science (<a class="reference external" href="https://arxiv.org/pdf/2111.13786.pdf">berkeley+lbnl+, 2021</a>)</p>
<ul class="simple">
<li><p>do more than predict what will happen, they attempt to offer insight into how or why</p></li>
<li><p><a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1359644621002816">AI-based language models powering drug discovery and development</a> (liu et al. 2021)</p></li>
<li><p>BioTranslator: Multilingual translation for zero-shot biomedical classification (<a class="reference external" href="https://www.nature.com/articles/s41467-023-36476-2">xu, woicik, poon, altman, &amp; wang, 2023</a>) - takes a user- written textual description of a new concept and then translates this description to a non-text biological data instance</p>
<ul>
<li><p>results for biological data, e.g. genes, proteins</p></li>
<li><p>enables the identification of novel cell types using only a textual description</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery (<a class="reference external" href="https://arxiv.org/abs/2305.14259">wang…hope, 2023</a>)</p>
<ul class="simple">
<li><p>literature-based discovery (<a class="reference external" href="https://www.journals.uchicago.edu/doi/abs/10.1086/601720">swanson, 1986</a>) - focus on predicting pairwise links between concepts from papers (e.g. drug-disease links)</p>
<ul>
<li><p>task 1: idea-sentence generation – given sentences describing background context + a seed term, generate a sentence describing an idea</p></li>
<li><p>task 2: idea-node prediction – given the background context, predict new links between existing concepts (and generate new concepts)</p></li>
</ul>
</li>
<li><p>forecasting paper titles (<a class="reference external" href="https://csinva.io/gpt-paper-title-generator/">blog post</a>)</p></li>
</ul>
</li>
<li><p>scientific organization (<a class="reference external" href="https://galactica.org/static/paper.pdf">galactica</a>)</p>
<ul>
<li><p>related but smaller models</p>
<ul class="simple">
<li><p>SciBERT (<a class="reference external" href="https://arxiv.org/abs/1903.10676">beltagy…cohan, 2019</a>)</p></li>
<li><p>BioLM (<a class="reference external" href="https://aclanthology.org/2020.clinicalnlp-1.17/">lewis…stoyanov, 2020</a>)</p></li>
<li><p>ScholarBERT (<a class="reference external" href="https://arxiv.org/abs/2205.11342">hong…foster, 2022</a>) - large dataset, 770M-param model</p></li>
</ul>
</li>
<li><p>all data is processed in a common markdown format</p></li>
<li><p>task-specific tokens to support different types of knowledge (e.g. citations, step-by-step reasoning, different modalities, e.g. proteins)</p></li>
<li><p>chemical compounds (train on 2 mil / 110 mil from PubChem Compound, authors still want it to focus on text)</p>
<ul>
<li><p>predict IUPAC name from SMILES formula e.g. <code class="docutils literal notranslate"><span class="pre">CC(C)(C)C(=O)N(CC1=NC(=CS1)C(=O)OC)C2CCCCC2</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">methyl</span> <span class="pre">2-[[cyclohexyl-(2,2-dimethylpropanoyl)]amino]</span> <span class="pre">methyl]thiazole-4-</span> </code></p></li>
<li><p><a class="reference external" href="https://moleculenet.org/datasets-1">moleculenet</a> (<a class="reference external" href="https://arxiv.org/abs/1703.00564">wu et al. 2017</a>) classification benchmark (6 tasks)</p>
<ul>
<li><p>training set examples are trained as text during fitting</p>
<ul class="simple">
<li><p>HIV - classify whether comopund inhibits HIV replication</p></li>
<li><p>BACE C - binding results (classification + regression) for BACE</p></li>
<li><p>BBBP - blood-brain barrier penetration(permeability) (binary classification)</p></li>
<li><p>Tox21 - qualitative toxicity on 12 targets (12-class multilabel binary)</p></li>
<li><p>SIDER - 27-class multi-class disorders in different organ systems</p></li>
<li><p>ClinTox - binary toxicity classification</p></li>
</ul>
</li>
<li><p>ex. for BBBP (one of the 6 tasks) - question is posed in different ways during training</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Here is a SMILES formula:   
   [START_I_SMILES]O=C(O)CCCC1=CC=C(N(CCCl)CCCl)C=C1[END_I_SMILES]
   
Question: Will the chemical compound penetrate the blood-brain barrier?
Answer: No
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</li>
<li><p>protein sequences</p>
<ul class="simple">
<li><p>from 227 million in UniProt, look at only 0.5 million subset (called Swiss-Prot)</p></li>
<li><p>evaluate protein sequence perplexity</p></li>
<li><p>protein keyword prediction (predict keywords in UniProt, like “ATP-Binding”, “Cell membrane”)</p></li>
<li><p>protein function description - compare free-form description to GT UniProt function description</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="tabular-data">
<h3><span class="section-number">1.9.4.4. </span>tabular data<a class="headerlink" href="#tabular-data" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>tabular pre-training</p>
<ul>
<li><p>TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second (<a class="reference external" href="https://arxiv.org/abs/2207.01848">hollman, …, hutter, 2022</a>)</p>
<ul>
<li><p>transformer takes in train + test dataset then outputs predictions</p></li>
<li><p>each row (data example) is treated as a token and test points attend only to training t</p>
<ul>
<li><p>takes fixed-size 100 columns, with zero-padded columns at the end (during training, randomly subsample columns)</p></li>
</ul>
</li>
<li><p>builds on prior-data fitted networks (PFNs) (<a class="reference external" href="https://arxiv.org/abs/2112.10510">muller, …, hutter, 2021</a>)</p></li>
<li><p>trained on synthetic data</p></li>
</ul>
</li>
<li><p>GPT for Semi-Automated Data Science: Introducing CAAFE for Context-Aware Automated Feature Engineering (<a class="reference external" href="https://arxiv.org/abs/2305.03403">hollman, …, hutter, 2023</a>)</p></li>
<li><p>TabDDPM: Modelling Tabular Data with Diffusion Models (<a class="reference external" href="https://arxiv.org/abs/2209.15421">2022</a>)</p></li>
<li><p>TabLLM: Few-shot Classification of Tabular Data with Large Language Models  (<a class="reference external" href="https://arxiv.org/abs/2210.10723">hegelsmann…, sontag, 2022</a>)</p></li>
<li><p><a class="reference external" href="https://www.semanticscholar.org/paper/TabRet%3A-Pre-training-Transformer-based-Tabular-for-Onishi-Oono/667b708db00c89eef062d8bc4a68f5364bf70648">TabRet: Pre-training Transformer-based Tabular Models for Unseen Columns</a></p></li>
<li><p>TABBIE (<a class="reference external" href="https://arxiv.org/abs/2105.02584">Iida, …, Iyyer, 2021</a>) - average row/column embeddings</p></li>
<li><p>(not using transformers): transform a relation table in a graph and perform random walks on the latter to produce node embeddings (<a class="reference external" href="https://dl.acm.org/doi/10.1145/3318464.3389742">Cappuzzo et al., 2020</a>)</p></li>
<li><p>Language models are weak learners (<a class="reference external" href="https://arxiv.org/abs/2306.14101">manikandan, jian, &amp; kolter, 2023</a>) - use prompted LLMs as weak learners in boosting algorithm for tabular data</p></li>
</ul>
</li>
<li><p>input representation</p>
<ul>
<li><p>baseline methods: usually flatten tables, maybe with special character for starting each row/col</p>
<ul>
<li><p>could combine output from rows/cols with using element-wise product, average pooling and concatenation (<a class="reference external" href="https://dl.acm.org/doi/10.1145/3447548.3467228">TABULARNET</a>)</p></li>
<li><p>sometimes add column headers to cell content</p></li>
<li><p>also popular is converting the table-to-text with finetuned models before processing</p></li>
</ul>
</li>
</ul>
</li>
<li><p>older</p>
<ul>
<li><p><a class="reference external" href="https://www.semanticscholar.org/paper/TaBERT%3A-Pretraining-for-Joint-Understanding-of-and-Yin-Neubig/a5b1d1cab073cb746a990b37d42dc7b67763f881">TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data</a> (yin, neubig, …, riedel, 2020)</p></li>
</ul>
</li>
<li><p>one-off tasks</p>
<ul>
<li><p>LLMS are realistic tabular data generators (<a class="reference external" href="https://arxiv.org/abs/2210.06280">borisov et al. 2022</a>)</p></li>
<li><p>Can Foundation Models Wrangle Your Data? (<a class="reference external" href="https://arxiv.org/abs/2205.09911">narayan…re, 2022</a>)</p></li>
</ul>
</li>
<li><p>reviews</p>
<ul>
<li><p>Transformers for Tabular Data Representation: A Survey of Models and Applications (<a class="reference external" href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00544/115239/Transformers-for-Tabular-Data-Representation-A">badaro…papotti, 2023</a>)</p>
<ul>
<li><p>common data sources: Wikipedia tables for QA (e.g. 3.2M tables in <a class="reference external" href="https://www.semanticscholar.org/paper/TabEL%3A-Entity-Linking-in-Web-Tables-Bhagavatula-Noraset/8ffcad9346c4978a211566fde6807d6fb4bfa5ed">this paper</a>) or WDC web table corpus (233M tables from <a class="reference external" href="https://dl.acm.org/doi/10.1145/2872518.2889386">lehmberg et al. 2016</a>)</p></li>
<li><p>modifications</p>
<ul>
<li><p>positional embeddings based on rows + cols</p></li>
<li><p>attention variants: add row-wise, sparse attention allows for adding more context</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.semanticscholar.org/paper/Table-Pre-training%3A-A-Survey-on-Model-Pretraining-Dong-Cheng/49f4b4ca86e574c7ec688cfd45d2e17ff079c313">Table Pre-training: A Survey on Model Architectures, Pretraining Objectives, and Downstream Tasks</a> (2022)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2302.11777">Embeddings for Tabular Data: A Survey</a> (singh &amp; bedathur, 2023)</p></li>
<li><p><a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/9998482/">Deep neural networks and tabular data: A survey</a> (2022) - mostly compares performance on standard tasks (e.g. classification)</p></li>
</ul>
</li>
</ul>
</section>
<section id="llm-limitations-perspectives">
<h3><span class="section-number">1.9.4.5. </span>llm limitations / perspectives<a class="headerlink" href="#llm-limitations-perspectives" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Dissociating language and thought in large language models: a cognitive perspective (<a class="reference external" href="https://arxiv.org/pdf/2301.06627.pdf">mahowald, …, tenenbaum, fedorenko, 2023</a>)</p>
<ul>
<li><p>2 competences: (1) formal &amp; (2) functional linguistic competence</p></li>
</ul>
</li>
<li><p>speculative <a class="reference external" href="https://arxiv.org/abs/2108.07258">foundation models paper</a> (stanford, 2022)</p></li>
</ul>
</section>
<section id="text-explanations-pre-cot">
<h3><span class="section-number">1.9.4.6. </span>text explanations (pre-CoT)<a class="headerlink" href="#text-explanations-pre-cot" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>WT5?! Training Text-to-Text Models to Explain their Predictions (<a class="reference external" href="https://arxiv.org/pdf/2004.14546.pdf">narang, raffel, …, malkan, 2020</a>)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1812.05634.pdf">Adversarial Inference for Multi-Sentence Video Description</a> - adversarial techniques during inference for a better multi-sentence video description</p></li>
<li><p><a class="reference external" href="https://aclweb.org/anthology/D18-1437">Object Hallucination in Image Captioning</a> - image relevance metric - asses rate of object hallucination</p>
<ul>
<li><p>CHAIR metric - what proportion of words generated are actually in the image according to gt sentences and object segmentations</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1803.09797.pdf">women also snowboard</a> - force caption models to look at people when making gender-specific predictions</p></li>
<li><p><a class="reference external" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Fooling_Vision_and_CVPR_2018_paper.pdf">Fooling Vision and Language Models Despite Localization and Attention Mechanism</a> -  can do adversarial attacks on captioning and VQA</p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1511.03745.pdf">Grounding of Textual Phrases in Images by Reconstruction</a> - given text and image provide a bounding box (supervised problem w/ attention)</p></li>
<li><p><a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/8791710">Natural Language Explanations of Classifier Behavior</a></p></li>
<li><p><a class="reference external" href="https://eli5.readthedocs.io/en/latest/libraries/sklearn.html#library-scikit-learn">eli5</a> has nice text highlighting for interp</p></li>
</ul>
</section>
<section id="clinical-papers">
<h3><span class="section-number">1.9.4.7. </span>clinical papers<a class="headerlink" href="#clinical-papers" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Self-Verification Improves Few-Shot Clinical Information Extraction (<a class="reference external" href="https://arxiv.org/abs/2306.00024">gero et al. 2023</a>)</p></li>
<li><p>Large Language Models are Few-Shot Clinical Information Extractors (<a class="reference external" href="https://arxiv.org/abs/2205.12689">agrawal…sontag, 2022</a>) - use GPT3</p></li>
<li><p>Health system-scale language models are all-purpose prediction engines (<a class="reference external" href="https://www.nature.com/articles/s41586-023-06160-y">NYU 2023</a>)</p></li>
<li><p>GPT4 in medicine book (<a class="reference external" href="https://www.amazon.com/AI-Revolution-Medicine-GPT-4-Beyond/dp/0138200130">lee, goldberg, &amp; kohane, 2023</a>)</p>
<ul>
<li><p>For summaries: “Can you check the proposed note and identify any facts in it that don’t appear explicitly in the transcript?”</p>
<ul>
<li><p>gpt often better at reviewing text than writing it</p></li>
</ul>
</li>
<li><p>evaluation</p>
<ul>
<li><p>hard to run gpt clinical trial, although can be used to identify candidates, e.g. biomarkers for followup tests</p></li>
</ul>
</li>
<li><p>paperwork - replace patient intake form, medical encounter note, prior authorization note (to insurance), universal translator for health info / formatting</p></li>
</ul>
</li>
<li><p>Evaluating Large Language Models on Medical Evidence Summarization (<a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/37162998/">tang…peng, 2023</a>) - score summaries based on 6 dimensions (e.g. coherence)</p>
<ul>
<li><p>Summarizing, Simplifying, and Synthesizing Medical Evidence Using GPT-3 (with Varying Success) (<a class="reference external" href="https://arxiv.org/abs/2305.06299">shaib…wallace, 2023</a>)</p></li>
<li><p>SummIt: Iterative Text Summarization via ChatGPT (<a class="reference external" href="https://arxiv.org/abs/2305.14835">zhang, …, zhang, 2023</a>)</p></li>
</ul>
</li>
</ul>
</section>
<section id="evaluating-with-llms">
<h3><span class="section-number">1.9.4.8. </span>evaluating with LLMs<a class="headerlink" href="#evaluating-with-llms" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment (<a class="reference external" href="https://arxiv.org/abs/2303.16634">liu…zhu, 2023, microsoft</a>) - ask for a score (1-5) in different categories, e.g. fluency, relevance, …</p></li>
<li><p>Human-like Summarization Evaluation with ChatGPT (<a class="reference external" href="https://arxiv.org/abs/2304.02554">gao…wan, 2023</a>) - prompt-based scoring of different categories, facts</p></li>
<li><p>Question-answering</p>
<ul>
<li><p>FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation (<a class="reference external" href="https://arxiv.org/abs/2305.14251">min…hajishirzi, 2023</a>) - breaks a generation into a series of facts and count what fraction of facts are supported by a reliable knowledge source</p></li>
<li><p>PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations (<a class="reference external" href="https://arxiv.org/abs/2307.02762">li…du, 2023</a>)</p></li>
</ul>
</li>
<li><p>Machine-translation</p>
<ul>
<li><p>Towards Explainable Evaluation Metrics for Machine Translation (<a class="reference external" href="https://arxiv.org/abs/2306.13041">leiter…eger, 2023</a>)</p></li>
</ul>
</li>
<li><p>General NLG</p>
<ul>
<li><p>ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate (<a class="reference external" href="https://arxiv.org/abs/2308.07201">chan…liu, 2023</a>)</p></li>
<li><p>AlignScore: Evaluating Factual Consistency with a Unified Alignment Function (<a class="reference external" href="https://arxiv.org/abs/2305.16739">zha…hu, 2023</a>) - train a model to explicitly evaluate factual consistency</p></li>
<li><p>Not All Metrics Are Guilty: Improving NLG Evaluation with LLM Paraphrasing (<a class="reference external" href="https://arxiv.org/abs/2305.15067">tang…wei, 2023</a>)</p></li>
</ul>
</li>
<li><p>Classical eval</p>
<ul>
<li><p>ROUGE, BLEU</p></li>
<li><p>BERTScore, BLEURTScore</p></li>
</ul>
</li>
</ul>
<p><strong>Trained llms</strong></p>
<ul class="simple">
<li><p>ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data and Comprehensive Evaluation (<a class="reference external" href="https://arxiv.org/abs/2306.09968">wang, …, li, 2023</a>)</p></li>
<li><p>BioGPT: <a class="reference external" href="https://academic.oup.com/bib/article-abstract/23/6/bbac409/6713511">Generative pre-trained transformer for biomedical text generation and mining</a> (luo…poon, liu, 2022)</p>
<ul>
<li><p>ChatDoctor (finetuned LLAMA) (<a class="reference external" href="https://arxiv.org/abs/2303.14070">yunxiang, …, you, 2023</a>)</p></li>
<li><p>PubMedGPT (2.7B): (<a class="reference external" href="https://crfm.stanford.edu/2022/12/15/pubmedgpt.html">bolton, hall, …, manning, liang, 2022</a>) -&gt; renamed to <em>BioMedLM</em></p></li>
<li><p>BioBERT: <a class="reference external" href="https://arxiv.org/abs/1901.08746">A pre-trained biomedical language representation model for biomedical text mining</a> (2019)</p></li>
<li><p>PubMedBERT: <a class="reference external" href="https://arxiv.org/abs/2007.15779">Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing</a> (gu…gao, poon, 2021)</p></li>
<li><p>Med-PaLM 2 (<a class="reference external" href="https://arxiv.org/abs/2305.09617">google, 2023</a>) - state of the art QA</p>
<ul>
<li><p>Large Language Models Encode Clinical Knowledge (<a class="reference external" href="https://arxiv.org/abs/2212.13138">singhal, …, natarajan, 2022, google/deepmind</a>) - introduce MultiMedQA dataset + derive Med-PaLM, a prompt-tuned version of PaLM</p></li>
</ul>
</li>
<li><p>PMC-LLaMA (<a class="reference external" href="https://arxiv.org/pdf/2304.14454.pdf">wu et al. 2023</a>)</p></li>
</ul>
</li>
</ul>
</section>
<section id="privacy">
<h3><span class="section-number">1.9.4.9. </span>privacy<a class="headerlink" href="#privacy" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Training Data Extraction From Pre-trained Language Models: A Survey (<a class="reference external" href="https://arxiv.org/abs/2305.16157">ishihara, 2023</a>)</p>
<ul>
<li><p>definitions</p>
<ul>
<li><p>(eidetic memorization). A string s is k-eidetic memorized by LLMf if a prompt p exists such that f(p) = s and s appears at most k times in the training set</p>
<ul>
<li><p>slightly different definition: A string s is k-memorized with k tokens of context from LLM f if a (length-k) string p exists such that the concatenation p + s is contained in the training set, and f produces s when prompted with p by using greedy decoding</p></li>
</ul>
</li>
<li><p><em>Differential privacy</em> = removing any data from the training set should not considerably change trained models</p></li>
<li><p><em>counterfactual memorization</em> = difference between a training data’s expected loss under a model that has and has not been trained on that data</p></li>
<li><p>some studies loosen the definition of memorization using a similarity metric for strings rather than exact string matching</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Extracting Training Data from Large Language Models (<a class="reference external" href="https://arxiv.org/abs/2012.07805">carlini, …, raffel, 2021</a>) - LLMs are particularly likely to memorize atypical data points</p>
<ul>
<li><p>Quantifying Memorization Across Neural Language Models (<a class="reference external" href="https://arxiv.org/abs/2202.07646">carlini, …, zhang, 2022</a>)</p></li>
<li><p>What does it mean for a language model to preserve privacy? (<a class="reference external" href="https://dl.acm.org/doi/abs/10.1145/3531146.3534642">brown, …, tramer, 2022</a>) - “privacy-preserving” LM should guarantee that a user’s data cannot ever appear (or be inferable) outside the context they originally expected it to appear in</p></li>
<li><p>Can Neural Network Memorization Be Localized? (<a class="reference external" href="https://arxiv.org/abs/2307.09542">maini, …, lipton, kolter, zhang, 2023</a>) - memorization is often confined to a small number of neurons or channels, propose example-tied dropout to direct memorization to few neurons</p></li>
</ul>
</li>
<li><p>Detecting Personal Information in Training Corpora: an Analysis (<a class="reference external" href="https://trustnlpworkshop.github.io/papers/28.pdf">subramani, luccioni, dodge, &amp; mitchell, 2023</a>)</p></li>
</ul>
</section>
<section id="paper-parsing">
<h3><span class="section-number">1.9.4.10. </span>paper parsing<a class="headerlink" href="#paper-parsing" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Nougat: Neural Optical Understanding for Academic Documents (<a class="reference external" href="https://arxiv.org/abs/2308.13418">blecher…scialom, sojnic, 2023</a>)</p></li>
<li><p>PDFTriage: Question Answering over Long, Structured Documents (<a class="reference external" href="https://arxiv.org/abs/2309.08872">adobe, 2023</a>)</p></li>
</ul>
</section>
</section>
<section id="basics">
<h2><span class="section-number">1.9.5. </span>basics<a class="headerlink" href="#basics" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><strong>attention</strong> = vector of importance weights</p>
<ul>
<li><p>to predict or infer one element, such as a pixel in an image or a word in a sentence, we estimate using the attention vector how strongly it is correlated with (or “<em>attends to</em>” other elements and take the sum of their values weighted by the attention vector as the approximation of the target</p></li>
</ul>
</li>
<li><p>vanilla transformer: multihead attention, add + norm, position-wise ffn, add + norm</p></li>
<li><p>self-attention layer <a class="reference external" href="https://github.com/mertensu/transformer-tutorial">implementation</a>, <a class="reference external" href="https://homes.cs.washington.edu/~thickstn/docs/transformers.pdf">mathematics</a>, and <strong>chandan’s self-attention <a class="reference external" href="https://slides.com/chandansingh-2/deck-51f404">cheat-sheet</a></strong></p></li>
</ul>
<section id="mathematical-overview-of-transformers-formal-algorithms-for-transformers">
<h3><span class="section-number">1.9.5.1. </span>mathematical overview of transformers (<a class="reference external" href="https://arxiv.org/abs/2207.09238?utm_source=substack&amp;utm_medium=email">Formal Algorithms for Transformers</a>)<a class="headerlink" href="#mathematical-overview-of-transformers-formal-algorithms-for-transformers" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>tasks</p>
<ul>
<li><p><em>sequence modeling</em>: learn <span class="math notranslate nohighlight">\(p(x)\)</span>, usually factorized as <span class="math notranslate nohighlight">\(p(x_i|x_1,...,x_{i-1})\)</span></p></li>
<li><p><em>sequence-to-sequence</em>: learn <span class="math notranslate nohighlight">\(p(z|x)\)</span>, e.g. transalation, speech-to-text, question answering</p></li>
</ul>
</li>
<li><p>preprocessing</p>
<ul>
<li><p>embedding matrix takes in one-hot tokens and linearly maps them to a vector</p></li>
<li><p>positional embedding of a token is usually added to the token embedding to form a token’s initial embedding</p></li>
</ul>
</li>
<li><p>attention types</p>
<ul>
<li><p><em>Bidirectional / unmasked self-attention</em> - primary/context vectors are the same</p></li>
<li><p><em>Unidirectional / masked self-attention</em> - mask scores from before a given word</p></li>
<li><p><em>Cross-attention</em> - primary/context vectors can come from different places</p></li>
</ul>
</li>
<li><p>non-attention</p>
<ul>
<li><p>layernorm: controls mean/variance of activations</p>
<ul>
<li><p>RMSnorm: simpler version, sets mean/offset to zero</p></li>
</ul>
</li>
</ul>
</li>
<li><p>unembedding</p>
<ul>
<li><p>linear layer (with softmax) that outputs size of original vocab</p>
<ul>
<li><p>sometimes fixed to be transpose of the embedding matrix</p></li>
</ul>
</li>
</ul>
</li>
<li><p>predictions</p>
<ul>
<li><p>predict next word using single linear layer on hidden state from previous word</p></li>
<li><p>finetune classification head often only using linear layer on first token from sequence</p></li>
</ul>
</li>
<li><p>architectures</p>
<ul>
<li><p>initially, encoder-decoder was common, but now often no decoder</p></li>
</ul>
</li>
</ul>
</section>
<section id="visual-explanation-notes-on-article-by-jay-allamar">
<h3><span class="section-number">1.9.5.2. </span>visual explanation (notes on article by jay allamar)<a class="headerlink" href="#visual-explanation-notes-on-article-by-jay-allamar" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>**self-attention ** - layer that lets word learn its relation to other layers</p>
<ul>
<li><p>for each word, want score telling how much importance to place on each other word (queries <span class="math notranslate nohighlight">\(\cdot\)</span> keys)</p></li>
<li><p>we get an encoding for each word</p>
<ul>
<li><p>the encoding of each word returns a weighted sum of the values of the words (the current word gets the highest weight)</p></li>
<li><p>softmax this and use it to do weighted sum of values<img alt="Screen Shot 2019-08-17 at 2.51.53 PM" src="../../_images/attention.png" /></p></li>
</ul>
</li>
<li><p>(optional) implementation details</p>
<ul>
<li><p><strong>multi-headed attention</strong> - just like having many filters, get many encodings for each word</p>
<ul>
<li><p>each one can take input as the embedding from the previous attention layer</p></li>
</ul>
</li>
<li><p><strong>position vector</strong> - add this into the embedding of each word (so words know how far apart they are) - usually use sin/cos rather than actual position number</p></li>
<li><p><strong>padding mask</strong> - add zeros to the end of the sequence</p></li>
<li><p><strong>look-ahead mask</strong> - might want to mask to only use previous words (e.g. if our final task is decoding)</p></li>
<li><p><strong>residual + normalize</strong> - after self-attention layer, often have residual connection to previous input, which gets added then normalized</p></li>
</ul>
</li>
<li><p>decoder - each word only allowed to attend to previous positions</p></li>
<li><p>3 components</p>
<ul>
<li><p>queries</p></li>
<li><p>keys</p></li>
<li><p>values</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>attention</strong></p>
<ul>
<li><p>encoder reads input and ouputs context vector after each word</p></li>
<li><p>decoder at each step uses a different weighted combination of these context vectors</p>
<ul>
<li><p>specifically, at each step, decoder concatenates its hidden state w/ the attention vector (the weighted combination of the context vectors)</p></li>
<li><p>this is fed to a feedforward net to output a word</p></li>
<li><p><img alt="Screen Shot 2019-04-11 at 7.57.14 PM" src="../../_images/nmt.png" /></p></li>
</ul>
</li>
<li><p>at a high level we have <span class="math notranslate nohighlight">\(Q, K, V\)</span> and compute <span class="math notranslate nohighlight">\(\text{softmax}(QK^T)V\)</span></p>
<ul>
<li><p>instead could simplify it and do <span class="math notranslate nohighlight">\(\text{softmax}(XX^T)V\)</span> - this would then be based on kernel</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>transformer</strong></p>
<ul>
<li><p>uses many self-attention layers</p></li>
<li><p>many stacked layers in encoder + decoder (not rnn: self-attention + feed forward)</p></li>
<li><p>details</p>
<ul>
<li><p>initial encoding: each word -&gt; vector</p></li>
<li><p>each layer takes a list of fixed size (hyperparameter e.g. length of longest sentence) and outputs a list of that same fixed size (so one output for each word)</p>
<ul>
<li><p>can easily train with a masked word to predict the word at the predicted position in the encoding</p></li>
</ul>
</li>
</ul>
</li>
<li><p>multi-headed attention has several of each of these (then just concat them)</p></li>
</ul>
</li>
</ul>
</section>
<section id="huggingface-tutorial">
<h3><span class="section-number">1.9.5.3. </span>huggingface tutorial<a class="headerlink" href="#huggingface-tutorial" title="Permalink to this headline">#</a></h3>
<p>Broadly, models can be grouped into three categories:</p>
<ul class="simple">
<li><p>GPT-like (also called <em>auto-regressive</em> Transformer models)</p></li>
<li><p>BERT-like (also called <em>auto-encoding</em> Transformer models)</p></li>
<li><p>BART/T5-like (also called <em>sequence-to-sequence</em> Transformer models)</p></li>
<li><p><a class="reference external" href="https://huggingface.co/course/chapter2/5?fw=pt">Handling multiple sequences - Hugging Face Course</a></p>
<ul>
<li><p>pad sequences to have the same length (need to modify attention masks to ignore the padded values)</p></li>
</ul>
</li>
</ul>
</section>
<section id="pre-transformer-nlp-models">
<h3><span class="section-number">1.9.5.4. </span>pre-transformer nlp models<a class="headerlink" href="#pre-transformer-nlp-models" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>rnns</p>
<ul>
<li><p>when training rnn, accumulate gradients over sequence and then update all at once</p></li>
<li><p><strong>stacked rnns</strong> have outputs of rnns feed into another rnn</p></li>
<li><p>bidirectional rnn - one rnn left to right and another right to left (can concatenate, add, etc.)</p></li>
</ul>
</li>
<li><p>standard seq2seq</p>
<ul>
<li><p>encoder reads input and outputs context vector (the hidden state)</p></li>
<li><p>decoder (rnn) takes this context vector and generates a sequence</p></li>
</ul>
</li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notes/research_ovws"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="ovw_ml_medicine.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">1.8. </span>ml in medicine</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="ovw_causal_inference.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">1.10. </span>causal inference</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Chandan Singh<br/>
  
      &copy; Copyright None.<br/>
    <div class="extra_footer">
      <p>
Many of these images are taken from resources on the web.
</p>
    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>